{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number of trials</th>\n",
       "      <th>number of parameters</th>\n",
       "      <th>type of function</th>\n",
       "      <th>accuracy [calc. max/ actual max]</th>\n",
       "      <th>time per trial [s]</th>\n",
       "      <th>type_of_opt</th>\n",
       "      <th>assigned_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.732417</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.638160</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.284646</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  number of trials  number of parameters type of function  \\\n",
       "0            0.0                16                     2             Trig   \n",
       "1            1.0                13                     2             Trig   \n",
       "2            2.0                10                     2             Trig   \n",
       "3            3.0                18                     2             Trig   \n",
       "4            4.0                11                     2             Trig   \n",
       "...          ...               ...                   ...              ...   \n",
       "1345         NaN                 8                     2             Trig   \n",
       "1346         NaN                 8                     2             Trig   \n",
       "1347         NaN                14                     2             Trig   \n",
       "1348         NaN                 9                     2             Trig   \n",
       "1349         NaN                10                     2             Trig   \n",
       "\n",
       "      accuracy [calc. max/ actual max]  time per trial [s] type_of_opt  \\\n",
       "0                             0.732417            0.009824       CmaEs   \n",
       "1                             0.983980            0.008316       CmaEs   \n",
       "2                             0.638160            0.007854       CmaEs   \n",
       "3                             0.952784            0.009196       CmaEs   \n",
       "4                             0.284646            0.007938       CmaEs   \n",
       "...                                ...                 ...         ...   \n",
       "1345                          0.034904            0.007662      CMA-ES   \n",
       "1346                          0.091423            0.010617      CMA-ES   \n",
       "1347                          0.015566            0.019561      CMA-ES   \n",
       "1348                          0.076210            0.011982      CMA-ES   \n",
       "1349                          0.028620            0.021816      CMA-ES   \n",
       "\n",
       "      assigned_class  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1345               0  \n",
       "1346               0  \n",
       "1347               0  \n",
       "1348               0  \n",
       "1349               0  \n",
       "\n",
       "[1350 rows x 8 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data/All Data combined.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.drop(['type_of_opt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['accuracy [calc. max/ actual max]'] < 1.05]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['number of trials','number of parameters','accuracy [calc. max/ actual max]', 'time per trial [s]']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['type_of_opt'].replace('CmaEs', 1,inplace=True)\n",
    "#df['type_of_opt'].replace('Random', 2,inplace=True)\n",
    "#df['type_of_opt'].replace('TPE', 3,inplace=True)\n",
    "y = df['assigned_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test = StandardScaler().fit(x_test).transform(x_test)\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 4)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,4), ncols = 4)\n",
    "ax[0].hist(x_train[:,0], bins = 20)\n",
    "ax[0].set_title('n_trials')\n",
    "ax[1].hist(x_train[:,1], bins = 20)\n",
    "ax[1].set_title('n_parameters')\n",
    "ax[2].hist(x_train[:,2], bins = 20)\n",
    "ax[2].set_title('accuracy')\n",
    "ax[3].hist(x_train[:,3], bins = 20)\n",
    "ax[3].set_title('time per trial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 5.175   \u001b[0m | \u001b[0m 44.04   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 45.99   \u001b[0m | \u001b[0m 22.8    \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 5.191   \u001b[0m | \u001b[0m 22.17   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6409  \u001b[0m | \u001b[95m 47.39   \u001b[0m | \u001b[95m 13.9    \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 22.86   \u001b[0m | \u001b[0m 41.86   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 46.53   \u001b[0m | \u001b[0m 47.66   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 41.72   \u001b[0m | \u001b[0m 24.05   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 44.1    \u001b[0m | \u001b[0m 2.801   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 42.53   \u001b[0m | \u001b[0m 26.18   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 20.24   \u001b[0m | \u001b[0m 26.72   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 28.59   \u001b[0m | \u001b[0m 48.62   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 43.78   \u001b[0m | \u001b[0m 5.681   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 47.28   \u001b[0m | \u001b[0m 8.359   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 47.92   \u001b[0m | \u001b[0m 20.67   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 3.779   \u001b[0m | \u001b[0m 37.44   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 39.68   \u001b[0m | \u001b[0m 41.57   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 27.14   \u001b[0m | \u001b[0m 30.26   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 42.48   \u001b[0m | \u001b[0m 2.42    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 34.09   \u001b[0m | \u001b[0m 29.99   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 10.85   \u001b[0m | \u001b[0m 28.26   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 47.01   \u001b[0m | \u001b[0m 15.18   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 47.66   \u001b[0m | \u001b[0m 13.21   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 46.71   \u001b[0m | \u001b[0m 13.88   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 45.63   \u001b[0m | \u001b[0m 47.34   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 47.0    \u001b[0m | \u001b[0m 46.56   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 34.46   \u001b[0m | \u001b[0m 28.91   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 34.8    \u001b[0m | \u001b[0m 30.9    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 33.13   \u001b[0m | \u001b[0m 30.05   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.6459  \u001b[0m | \u001b[95m 47.44   \u001b[0m | \u001b[95m 47.49   \u001b[0m |\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m 0.6484  \u001b[0m | \u001b[95m 47.45   \u001b[0m | \u001b[95m 48.58   \u001b[0m |\n",
      "| \u001b[95m 31      \u001b[0m | \u001b[95m 0.6509  \u001b[0m | \u001b[95m 48.28   \u001b[0m | \u001b[95m 48.16   \u001b[0m |\n",
      "| \u001b[95m 32      \u001b[0m | \u001b[95m 0.6633  \u001b[0m | \u001b[95m 48.3    \u001b[0m | \u001b[95m 49.2    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 49.01   \u001b[0m | \u001b[0m 49.08   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 48.07   \u001b[0m | \u001b[0m 49.7    \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 12.32   \u001b[0m | \u001b[0m 28.09   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 15.85   \u001b[0m | \u001b[0m 42.2    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 48.2    \u001b[0m | \u001b[0m 48.81   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 47.49   \u001b[0m | \u001b[0m 48.62   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 12.11   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 46.49   \u001b[0m | \u001b[0m 47.73   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 48.34   \u001b[0m | \u001b[0m 48.16   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 37.72   \u001b[0m | \u001b[0m 43.3    \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 16.14   \u001b[0m | \u001b[0m 42.01   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 33.67   \u001b[0m | \u001b[0m 13.6    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 37.87   \u001b[0m | \u001b[0m 46.22   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 18.87   \u001b[0m | \u001b[0m 13.68   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 38.02   \u001b[0m | \u001b[0m 46.22   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 37.96   \u001b[0m | \u001b[0m 46.34   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 47.93   \u001b[0m | \u001b[0m 20.63   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 20.89   \u001b[0m | \u001b[0m 26.87   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 48.30125452904918, f: 0.6209476309226932\n",
      "Found y: 49.19729969225779, f: 0.6309226932668329\n",
      "Max value found is: 0.6408977556109726\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    estimator = DecisionTreeClassifier(max_depth= int(np.round(x)))\n",
    "    clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(y)))\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    yhat = clf.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=int(np.round(found_x)))\n",
    "clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(found_y)))\n",
    "clf = clf.fit(x_train, y_train)\n",
    "yhat = clf.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408977556109726"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0.4, 0. ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0,0.4,0]).reshape(1,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 33.01   \u001b[0m | \u001b[0m 17.52   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.586   \u001b[0m | \u001b[95m 96.41   \u001b[0m | \u001b[95m 73.55   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 64.97   \u001b[0m | \u001b[0m 6.881   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 15.86   \u001b[0m | \u001b[0m 98.89   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 89.47   \u001b[0m | \u001b[0m 27.02   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 19.28   \u001b[0m | \u001b[0m 22.15   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 15.22   \u001b[0m | \u001b[0m 59.14   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 62.31   \u001b[0m | \u001b[0m 95.94   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 44.23   \u001b[0m | \u001b[0m 20.45   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.5935  \u001b[0m | \u001b[95m 49.15   \u001b[0m | \u001b[95m 34.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 59.15   \u001b[0m | \u001b[0m 40.86   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 37.07   \u001b[0m | \u001b[0m 36.85   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 94.04   \u001b[0m | \u001b[0m 34.58   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 75.26   \u001b[0m | \u001b[0m 5.944   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 32.09   \u001b[0m | \u001b[0m 88.23   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 21.8    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 45.84   \u001b[0m | \u001b[0m 17.02   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5387  \u001b[0m | \u001b[0m 2.095   \u001b[0m | \u001b[0m 53.26   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5636  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 33.33   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 81.09   \u001b[0m | \u001b[0m 9.12    \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 46.0    \u001b[0m | \u001b[0m 39.79   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 54.41   \u001b[0m | \u001b[0m 33.39   \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 0.596   \u001b[0m | \u001b[95m 45.54   \u001b[0m | \u001b[95m 33.28   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 47.85   \u001b[0m | \u001b[0m 30.37   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 40.94   \u001b[0m | \u001b[0m 32.65   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 97.47   \u001b[0m | \u001b[0m 79.67   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 90.96   \u001b[0m | \u001b[0m 77.68   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5636  \u001b[0m | \u001b[0m 89.83   \u001b[0m | \u001b[0m 69.3    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 92.38   \u001b[0m | \u001b[0m 85.2    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 97.18   \u001b[0m | \u001b[0m 88.71   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 87.05   \u001b[0m | \u001b[0m 85.48   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5636  \u001b[0m | \u001b[0m 94.3    \u001b[0m | \u001b[0m 81.66   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 91.74   \u001b[0m | \u001b[0m 87.59   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 46.19   \u001b[0m | \u001b[0m 35.11   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 99.01   \u001b[0m | \u001b[0m 76.58   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 95.14   \u001b[0m | \u001b[0m 76.81   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 50.57   \u001b[0m | \u001b[0m 37.62   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 47.78   \u001b[0m | \u001b[0m 32.72   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 90.73   \u001b[0m | \u001b[0m 84.21   \u001b[0m |\n",
      "| \u001b[95m 40      \u001b[0m | \u001b[95m 0.5985  \u001b[0m | \u001b[95m 43.97   \u001b[0m | \u001b[95m 31.6    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 43.48   \u001b[0m | \u001b[0m 28.11   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5686  \u001b[0m | \u001b[0m 99.77   \u001b[0m | \u001b[0m 72.12   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 43.48   \u001b[0m | \u001b[0m 33.63   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 45.38   \u001b[0m | \u001b[0m 31.29   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5561  \u001b[0m | \u001b[0m 42.58   \u001b[0m | \u001b[0m 30.53   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 47.88   \u001b[0m | \u001b[0m 34.82   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 44.35   \u001b[0m | \u001b[0m 32.38   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 46.78   \u001b[0m | \u001b[0m 33.47   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 45.24   \u001b[0m | \u001b[0m 34.18   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 91.36   \u001b[0m | \u001b[0m 85.59   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 43.966635178925394, f: 0.5561097256857855\n",
      "Found y: 31.598335475671462, f: 0.5935162094763092\n",
      "Max value found is: 0.5411471321695761\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    rfr = RandomForestClassifier(max_depth = int(np.round(x)), n_estimators = int(np.round(y)), max_features = 4)\n",
    "    rfr = rfr.fit(x_train, y_train.flatten())\n",
    "    yhat = rfr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 100\n",
    "ymin = 1\n",
    "ymax = 100\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=4)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestClassifier(max_depth = int(np.round(found_x)), n_estimators = int(np.round(found_y)), max_features = 4)\n",
    "rfr = rfr.fit(x_train, y_train.flatten())\n",
    "yhat = rfr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2468827930174564"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57356608478803"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 43.54   \u001b[0m | \u001b[0m 38.76   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6135  \u001b[0m | \u001b[95m 36.1    \u001b[0m | \u001b[95m 7.907   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 27.7    \u001b[0m | \u001b[0m 14.3    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 2.98    \u001b[0m | \u001b[0m 19.92   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5586  \u001b[0m | \u001b[0m 11.01   \u001b[0m | \u001b[0m 18.39   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 17.5    \u001b[0m | \u001b[0m 28.94   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 30.86   \u001b[0m | \u001b[0m 40.26   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 25.1    \u001b[0m | \u001b[0m 28.37   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 36.97   \u001b[0m | \u001b[0m 16.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 22.97   \u001b[0m | \u001b[0m 20.89   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 15.54   \u001b[0m | \u001b[0m 12.23   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 36.57   \u001b[0m | \u001b[0m 29.02   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 37.7    \u001b[0m | \u001b[0m 39.65   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 45.51   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 24.86   \u001b[0m | \u001b[0m 32.98   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 8.138   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5362  \u001b[0m | \u001b[0m 1.773   \u001b[0m | \u001b[0m 27.95   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 28.59   \u001b[0m | \u001b[0m 8.707   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 45.89   \u001b[0m | \u001b[0m 13.92   \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.6185  \u001b[0m | \u001b[95m 5.453   \u001b[0m | \u001b[95m 3.903   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.6284  \u001b[0m | \u001b[95m 44.46   \u001b[0m | \u001b[95m 5.567   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 42.13   \u001b[0m | \u001b[0m 9.403   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 40.17   \u001b[0m | \u001b[0m 2.959   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 0.6309  \u001b[0m | \u001b[95m 49.63   \u001b[0m | \u001b[95m 8.509   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 49.42   \u001b[0m | \u001b[0m 1.145   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 9.995   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 33.25   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 3.577   \u001b[0m | \u001b[0m 9.104   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 44.04   \u001b[0m | \u001b[0m 1.162   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 20.06   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 24.89   \u001b[0m | \u001b[0m 1.071   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 21.47   \u001b[0m | \u001b[0m 8.093   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 48.59   \u001b[0m | \u001b[0m 5.062   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 46.6    \u001b[0m | \u001b[0m 9.29    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5262  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 49.91   \u001b[0m | \u001b[0m 12.26   \u001b[0m |\n",
      "| \u001b[95m 40      \u001b[0m | \u001b[95m 0.6359  \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 3.174   \u001b[0m |\n",
      "| \u001b[95m 41      \u001b[0m | \u001b[95m 0.6459  \u001b[0m | \u001b[95m 32.35   \u001b[0m | \u001b[95m 4.809   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 34.81   \u001b[0m | \u001b[0m 4.65    \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 37.0    \u001b[0m | \u001b[0m 49.78   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 32.67   \u001b[0m | \u001b[0m 6.54    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 39.37   \u001b[0m | \u001b[0m 6.305   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 18.94   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 25.99   \u001b[0m | \u001b[0m 5.279   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 31.45   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.5212  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 38.43   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 22.59   \u001b[0m | \u001b[0m 13.42   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 32.3499628455739, f: 0.6408977556109726\n",
      "Found y: 4.80912996056861, f: 0.6234413965087282\n",
      "Max value found is: 0.6359102244389028\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    gbr = GradientBoostingClassifier(n_estimators = int(np.round(x)), max_depth = int(np.round(y)), learning_rate = 0.1)\n",
    "    gbr = gbr.fit(x_train, y_train.flatten())\n",
    "    yhat = gbr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators = int(np.round(found_x)), max_depth = int(np.round(found_y)), learning_rate = 0.1)\n",
    "gbr = gbr.fit(x_train, y_train.flatten())\n",
    "yhat = gbr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3216957605985038"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408977556109726"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ensemble_methods import Decision_Tree_Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6608478802992519"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decision_Tree_Classifier(0.8,1,1,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run the predictions from the Ensemble method to generate predictions based on the number of trials, accuracy, and time of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(b):\n",
    "    n = 11 #Number of points per dimension. Number of trials = n^3\n",
    "    prediction_list = []\n",
    "    prediction_parameters = []\n",
    "    for k in range(n):\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                a = k/(n-1)\n",
    "                c = j/(n-1)\n",
    "                d = i/(n-1)\n",
    "                predict_array = np.array([a,b,c,d]).reshape(1,-1)\n",
    "                prediction = clf.predict(predict_array)\n",
    "                prediction_parameters.append([a,c,d])\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "    p_class = np.asarray(prediction_list)\n",
    "    p_parameters = np.asarray(prediction_parameters)\n",
    "    data = np.hstack((p_parameters, p_class))\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, view_angle_h, view_angle_v):\n",
    "    cols = ['Trials', 'Accuracy', 'Time', 'Class']\n",
    "    df = pd.DataFrame(data, columns = cols)\n",
    "    \n",
    "    class_0_data = np.asarray(df[df['Class'] == 0.])\n",
    "    class_1_data = np.asarray(df[df['Class'] == 1.])\n",
    "    class_2_data = np.asarray(df[df['Class'] == 2.])\n",
    "    class_3_data = np.asarray(df[df['Class'] == 3.])\n",
    "    class_4_data = np.asarray(df[df['Class'] == 4.])\n",
    "    \n",
    "    plt.close()\n",
    "    fig = plt.subplots(figsize=(15,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    xline_0 = class_0_data[:,0]\n",
    "    yline_0 = class_0_data[:,1]\n",
    "    zline_0 = class_0_data[:,2]\n",
    "    ax.scatter3D(xline_0, yline_0, zline_0, color = 'b', marker='o', s=300, alpha = 0.25, label = 'CmaEs')\n",
    "\n",
    "    xline_1 = class_1_data[:,0]\n",
    "    yline_1 = class_1_data[:,1]\n",
    "    zline_1 = class_1_data[:,2]\n",
    "    ax.scatter3D(xline_1, yline_1, zline_1, color = 'm', marker='o', s=300, alpha = 0.25, label = 'Random')\n",
    "\n",
    "    xline_2 = class_2_data[:,0]\n",
    "    yline_2 = class_2_data[:,1]\n",
    "    zline_2 = class_2_data[:,2]\n",
    "    ax.scatter3D(xline_2, yline_2, zline_2, color = 'g', marker='o', s =300, alpha = 0.25, label = 'TPE')\n",
    "\n",
    "    xline_3 = class_3_data[:,0]\n",
    "    yline_3 = class_3_data[:,1]\n",
    "    zline_3 = class_3_data[:,2]\n",
    "    ax.scatter3D(xline_3, yline_3, zline_3, color = 'r', marker='o', s=300, alpha = 0.25, label = 'Bayes')\n",
    "\n",
    "    xline_4 = class_4_data[:,0]\n",
    "    yline_4 = class_4_data[:,1]\n",
    "    zline_4 = class_4_data[:,2]\n",
    "    ax.scatter3D(xline_4, yline_4, zline_4, color = 'y', marker='o', s=300, alpha = 0.25, label = 'L-BFGS-B')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    ax.set_xlabel('Number of Trials')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Time per Iteration')\n",
    "    ax.view_init(elev= view_angle_v, azim=view_angle_h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = generate_data(0)\n",
    "data_1 = generate_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c27e02b38b46fe815c6e8dfe2b2aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=40, description='Rotate_View_h', max=360, min=40, step=20), IntSlider(vaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0)>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "def update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0):\n",
    "    if N_of_Params == 0:\n",
    "        plot_data(data_0, Rotate_View_h, Rotate_View_v)\n",
    "    else:\n",
    "        plot_data(data_1, Rotate_View_h, Rotate_View_v)\n",
    "interact(update, Rotate_View_h = (40,360,20), Rotate_View_v = (10,360,20), N_of_Params = (0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., ..., 4., 4., 4.])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
