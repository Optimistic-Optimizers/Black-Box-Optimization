{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "moving-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn import neighbors, datasets, svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('GTKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-agenda",
   "metadata": {},
   "source": [
    "pip install xlrd==1.2.0.  (latest version of xlrd only imports .xls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "political-capture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_excel ('Black-Box-Optimization/Data/number_of_parameters_2.xlsx')\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-association",
   "metadata": {},
   "source": [
    "The KNN classifier works on assigning the probability membership in a specifc class based on the distance to other members in a class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-hunter",
   "metadata": {},
   "source": [
    "The KNN algorithm randomly takes 80% of the data for training (X_train) and 20% of the data for testing (X_test). Inorder to make the randomization cosistent every time the model is run, a seed of 14 is chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-rental",
   "metadata": {},
   "source": [
    "After fitting the data into the algorithm, the model predicts the assigned_class of the optimzer inroder to help the user chose the type of optimzer they want to utilize for theor specific needs. i.e type of function, number of parametrs, accuracy and time per trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "divided-stereo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-36f5b1f1bff7>:1: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  df = pd.read_excel ('data/All Data combined.xlsx')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel ('data/All Data combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "unavailable-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organized-improvement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "measured-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481\n"
     ]
    }
   ],
   "source": [
    "X = df[['number of trials','accuracy [calc. max/ actual max]','time per trial [s]']]\n",
    "y = df['assigned_class']\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dimensional-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184 297\n"
     ]
    }
   ],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14) #14 is seed\n",
    "\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "religious-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit(X_train).transform(X_train)\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test)\n",
    "#X_train = MinMaxScaler().fit(X_train).transform(X_train)\n",
    "#X_test = MinMaxScaler().fit(X_test).transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dress-austin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83094855, -0.3309303 ,  0.88631636],\n",
       "       [-1.80149645, -1.43484657, -0.47215367],\n",
       "       [ 1.4890598 , -1.39066252, -0.45712038],\n",
       "       [ 0.83094855,  0.16504603, -0.4736127 ],\n",
       "       [-0.92401479, -0.21582207, -0.48093728],\n",
       "       [ 0.1728373 ,  0.66843307, -0.45730025],\n",
       "       [-0.04653312, -0.85260367, -0.48168787],\n",
       "       [-1.80149645,  0.0925481 , -0.48091341],\n",
       "       [-0.26590354, -0.82947756, -0.42197313],\n",
       "       [ 1.4890598 ,  1.20925106,  0.4871487 ],\n",
       "       [-0.04653312,  0.36801853, -0.4668838 ],\n",
       "       [ 1.05031896,  1.20925106, -0.15266484],\n",
       "       [ 0.61157813, -1.14343681,  0.83598965],\n",
       "       [-0.48527395, -1.39739706, -0.47726315],\n",
       "       [ 1.4890598 , -0.56317921,  0.44440965],\n",
       "       [ 0.61157813, -1.3874822 , -0.42591268],\n",
       "       [ 1.05031896, -0.56556129, -0.48113768],\n",
       "       [ 0.39220771, -0.0588771 , -0.47952282],\n",
       "       [ 0.83094855,  0.06022101, -0.4740099 ],\n",
       "       [ 1.26968938, -1.19078194,  0.8982723 ],\n",
       "       [-0.70464437,  1.20842454,  4.05802373],\n",
       "       [ 2.14717105,  0.14698322, -0.44157236],\n",
       "       [ 0.61157813, -0.2276639 , -0.42245002],\n",
       "       [ 0.83094855, -0.10316899, -0.47193229],\n",
       "       [-0.48527395, -1.14932964, -0.46780759],\n",
       "       [-1.58212603, -0.70024029, -0.46469502],\n",
       "       [-0.70464437,  1.18335365, -0.32070466],\n",
       "       [ 0.1728373 , -1.4126102 , -0.4690091 ],\n",
       "       [-0.26590354, -1.19036279, -0.28985651],\n",
       "       [ 1.70843021,  1.18830239, -0.38361572],\n",
       "       [ 0.1728373 ,  0.59698151, -0.47820425],\n",
       "       [ 1.05031896,  1.13071872,  1.09591091],\n",
       "       [ 1.05031896,  0.7789422 , -0.46190167],\n",
       "       [ 1.26968938,  1.20925106,  0.83492003],\n",
       "       [ 0.61157813,  0.8641519 , -0.46889603],\n",
       "       [-1.58212603, -0.76076791, -0.46555636],\n",
       "       [-0.04653312, -1.3004255 , -0.46141571],\n",
       "       [-0.04653312,  1.19900643, -0.27793947],\n",
       "       [-0.26590354, -1.17777256, -0.4639526 ],\n",
       "       [-0.92401479, -1.39574803, -0.46440767],\n",
       "       [-0.26590354,  0.21624914, -0.48620567],\n",
       "       [-1.36275562,  1.14187533, -0.47813089],\n",
       "       [ 0.39220771,  1.20925106,  1.60618038],\n",
       "       [ 0.83094855,  1.16508406, -0.43125083],\n",
       "       [-1.36275562, -0.5262775 , -0.47900298],\n",
       "       [-1.1433852 , -1.37534039, -0.45944724],\n",
       "       [ 1.05031896,  1.2052084 , -0.36917556],\n",
       "       [-0.04653312,  0.1282605 , -0.47782105],\n",
       "       [-0.48527395,  1.20925106,  1.72533205],\n",
       "       [-1.36275562, -0.77771523, -0.32882378],\n",
       "       [-0.92401479, -1.3905876 , -0.40458579],\n",
       "       [ 0.1728373 ,  0.22430795, -0.45657558],\n",
       "       [-0.92401479, -0.42615502, -0.46317393],\n",
       "       [-0.92401479, -1.14462495, -0.47541621],\n",
       "       [-1.58212603, -1.43484657, -0.45798432],\n",
       "       [-0.70464437,  1.20757309, -0.34582822],\n",
       "       [-0.48527395, -0.75522557, -0.46722557],\n",
       "       [-1.80149645, -1.43484657, -0.47628418],\n",
       "       [ 0.61157813,  1.2075027 , -0.30145313],\n",
       "       [-0.04653312, -1.42033835, -0.45644505],\n",
       "       [ 0.39220771,  0.24316216, -0.47829782],\n",
       "       [-0.04653312,  0.87392747, -0.46702941],\n",
       "       [-1.1433852 , -1.12013731, -0.46934476],\n",
       "       [ 0.39220771,  1.20925106,  1.42700596],\n",
       "       [-0.48527395,  1.20925106,  1.771634  ],\n",
       "       [-1.58212603,  0.45687289, -0.46213472],\n",
       "       [-0.48527395,  1.20925106, -0.32104367],\n",
       "       [ 1.4890598 ,  0.44894284, -0.42350579],\n",
       "       [ 0.61157813, -0.49386222, -0.46589848],\n",
       "       [ 1.05031896, -0.96301871, -0.46712416],\n",
       "       [-1.58212603, -0.36005375, -0.45417722],\n",
       "       [ 1.70843021,  1.13071872,  0.78878837],\n",
       "       [ 1.92780063, -0.35903058, -0.46872967],\n",
       "       [ 0.39220771,  1.20925106,  0.97602429],\n",
       "       [-0.04653312,  1.00219244, -0.47049167],\n",
       "       [-0.70464437,  1.20925102, -0.42085801],\n",
       "       [-0.48527395, -0.3529792 , -0.46592834],\n",
       "       [-0.04653312,  1.20925106, -0.28851355],\n",
       "       [-0.92401479,  0.63911995, -0.46967463],\n",
       "       [-2.02086687, -1.43484657, -0.45633772],\n",
       "       [ 0.39220771,  0.60554386, -0.44588278],\n",
       "       [ 0.61157813,  1.18547829, -0.43318111],\n",
       "       [-0.04653312, -0.61271224, -0.46675096],\n",
       "       [-0.26590354,  0.93573156, -0.44517818],\n",
       "       [ 1.70843021, -1.19078194,  0.31064111],\n",
       "       [ 1.05031896,  1.20925106, -0.19966644],\n",
       "       [ 0.61157813,  1.10899031, -0.4415573 ],\n",
       "       [-1.1433852 , -0.58365164, -0.4757137 ],\n",
       "       [-2.02086687, -1.43484657, -0.45693078],\n",
       "       [ 0.1728373 , -1.15322501, -0.47065466],\n",
       "       [-2.02086687, -1.42122864, -0.47111938],\n",
       "       [ 0.39220771, -0.61877414, -0.44920636],\n",
       "       [-0.04653312,  1.20739687, -0.3028198 ],\n",
       "       [-0.04653312,  1.20925106,  2.12311316],\n",
       "       [-0.70464437, -1.40056385, -0.47818209],\n",
       "       [ 1.26968938, -1.41268282, -0.48039939],\n",
       "       [-0.70464437,  0.38914824,  2.92120297],\n",
       "       [ 1.92780063,  1.20925106,  0.33540382],\n",
       "       [-0.04653312, -1.42708503, -0.46329271],\n",
       "       [-0.04653312,  0.6217074 , -0.45310529],\n",
       "       [ 0.39220771, -0.55105072, -0.47149271],\n",
       "       [ 0.83094855, -1.28683109, -0.46786528],\n",
       "       [ 0.1728373 , -0.78035146, -0.48195962],\n",
       "       [ 2.58591188,  1.19920521, -0.41844625],\n",
       "       [-2.02086687, -0.32339283, -0.45905325],\n",
       "       [ 1.4890598 ,  0.32168868, -0.47163846],\n",
       "       [ 1.4890598 , -0.56317921,  0.59146135],\n",
       "       [ 1.05031896,  1.20925106,  1.08656873],\n",
       "       [ 1.26968938,  0.54653848, -0.46848902],\n",
       "       [ 0.39220771, -1.42253781, -0.48143074],\n",
       "       [-1.58212603, -1.1400455 , -0.46945261],\n",
       "       [ 0.61157813, -1.42517215, -0.46166987],\n",
       "       [-2.02086687, -1.43484657, -0.43653934],\n",
       "       [ 0.1728373 ,  1.20925104, -0.38722496],\n",
       "       [-0.26590354,  0.05314477, -0.46607091],\n",
       "       [-0.92401479,  0.81141551, -0.48142805],\n",
       "       [-0.26590354,  1.20925106,  1.55300384],\n",
       "       [ 2.14717105, -1.28103212, -0.46906607],\n",
       "       [ 0.61157813,  0.56601517, -0.46987839],\n",
       "       [ 1.70843021,  1.20925106,  0.39861956],\n",
       "       [-0.04653312, -1.36993926, -0.47706155],\n",
       "       [ 1.92780063,  1.13071873,  0.73628173],\n",
       "       [ 2.58591188,  0.78054699, -0.40417891],\n",
       "       [ 0.1728373 , -0.1690762 , -0.47974364],\n",
       "       [-0.26590354,  1.16488368, -0.46793205],\n",
       "       [-0.26590354, -1.41475244, -0.47901379],\n",
       "       [-0.48527395, -0.80037796, -0.46648321],\n",
       "       [ 1.70843021, -0.0193118 , -0.45783022],\n",
       "       [ 3.02465271, -1.40584374, -0.4639375 ],\n",
       "       [ 0.61157813, -1.40945263, -0.442079  ],\n",
       "       [ 0.83094855,  1.20750777, -0.33891018],\n",
       "       [-0.48527395, -0.19388311, -0.46628308],\n",
       "       [ 1.4890598 ,  1.20925106,  0.48415684],\n",
       "       [ 0.39220771,  1.20925106,  1.04856964],\n",
       "       [-1.1433852 ,  1.20925106,  3.25963881],\n",
       "       [-1.36275562, -1.38444307, -0.45488785],\n",
       "       [-1.58212603, -1.42926274, -0.47316808],\n",
       "       [-1.1433852 , -1.42070679, -0.46779305],\n",
       "       [ 0.61157813,  1.16816169, -0.44088421],\n",
       "       [-0.92401479, -0.84614667, -0.44566789],\n",
       "       [-1.1433852 , -0.11402971, -0.47585265],\n",
       "       [-0.04653312,  1.20925106,  1.29993232],\n",
       "       [ 0.39220771,  1.20925106,  1.53627466],\n",
       "       [-0.26590354,  1.20740651, -0.26581253],\n",
       "       [ 0.1728373 ,  1.20925106,  1.06372476],\n",
       "       [-0.92401479,  1.20687811, -0.30301186],\n",
       "       [-1.80149645, -0.96413206, -0.46686834],\n",
       "       [-0.26590354,  1.20925106,  1.52084743],\n",
       "       [ 1.05031896,  1.20925106,  0.64943395],\n",
       "       [-0.92401479,  1.20842454,  4.29363386],\n",
       "       [-0.70464437,  1.20925106,  2.08780698],\n",
       "       [-0.92401479,  1.20925106,  2.58573946],\n",
       "       [ 0.39220771,  0.197937  , -0.46209362],\n",
       "       [-0.92401479, -1.10508786, -0.39796064],\n",
       "       [ 0.39220771,  0.81156355, -0.45160495],\n",
       "       [ 1.26968938,  1.19511243, -0.4657902 ],\n",
       "       [-1.36275562, -1.43484657, -0.45610855],\n",
       "       [ 0.83094855, -1.20882747, -0.47108607],\n",
       "       [-0.04653312,  0.60670685, -0.47131335],\n",
       "       [-0.04653312, -1.39045832, -0.46272115],\n",
       "       [-0.04653312, -1.20699629, -0.45996572],\n",
       "       [-0.92401479, -0.07385026, -0.4754846 ],\n",
       "       [ 1.05031896,  0.41020988, -0.42829326],\n",
       "       [-1.1433852 , -1.00763342, -0.47615313],\n",
       "       [ 0.61157813,  0.28508695, -0.46846838],\n",
       "       [-0.92401479, -1.42895433, -0.45612641],\n",
       "       [ 1.05031896,  1.04052859, -0.44129454],\n",
       "       [-1.1433852 ,  1.13789511, -0.45330328],\n",
       "       [ 1.26968938, -1.38815749, -0.46633645],\n",
       "       [ 1.05031896,  0.5031881 , -0.46203118],\n",
       "       [ 0.39220771, -1.24236706, -0.47190365],\n",
       "       [-0.26590354, -1.20071561, -0.41729372],\n",
       "       [ 0.83094855, -0.24248916, -0.43004575],\n",
       "       [-0.26590354,  1.20925106,  1.52815925],\n",
       "       [-0.26590354,  1.2090329 , -0.36711671],\n",
       "       [ 1.26968938,  1.20740651, -0.38563272],\n",
       "       [-0.70464437, -0.52114642, -0.45393035],\n",
       "       [ 0.39220771, -1.35751641, -0.47923624],\n",
       "       [ 1.70843021, -1.19078194,  0.31591215],\n",
       "       [-0.26590354, -1.2141341 , -0.47541087],\n",
       "       [-0.26590354,  0.73975174, -0.47379676],\n",
       "       [-0.04653312,  1.20925106,  2.11083059],\n",
       "       [-0.26590354,  1.20925106,  2.23807322],\n",
       "       [ 0.1728373 ,  1.20711316, -0.21482872],\n",
       "       [ 1.26968938,  0.39737486, -0.42173412],\n",
       "       [-0.26590354, -0.07382758, -0.46300553],\n",
       "       [ 1.05031896,  0.98540838, -0.47173259],\n",
       "       [ 1.70843021, -0.50989775, -0.44424521],\n",
       "       [ 0.1728373 , -1.15209734, -0.4058084 ],\n",
       "       [ 0.39220771,  1.20925106, -0.22874915],\n",
       "       [-1.1433852 , -1.07561701,  3.30406663],\n",
       "       [ 0.61157813, -1.39237934, -0.48186253],\n",
       "       [-1.80149645,  0.18772675, -0.44827493],\n",
       "       [ 0.83094855,  1.19009082, -0.45678975],\n",
       "       [-0.48527395, -1.07052019, -0.47487409],\n",
       "       [ 0.1728373 ,  0.39460748, -0.45432732],\n",
       "       [-0.92401479, -0.20665224, -0.46596474],\n",
       "       [ 0.1728373 ,  1.20925106,  1.86666645],\n",
       "       [ 0.61157813,  1.20925106, -0.36960672],\n",
       "       [-0.48527395, -1.1514034 ,  2.019383  ],\n",
       "       [ 1.05031896,  1.20925106,  1.03110868],\n",
       "       [ 0.39220771,  0.97409434, -0.47897857],\n",
       "       [-0.48527395, -1.41956653, -0.47932674],\n",
       "       [-0.70464437,  1.20842454,  4.10136565],\n",
       "       [-0.70464437,  1.20925106,  2.08686876],\n",
       "       [ 0.1728373 , -1.41985271, -0.45254294],\n",
       "       [ 0.61157813,  0.73995681, -0.42741027],\n",
       "       [-1.36275562,  1.20925106,  3.84610713],\n",
       "       [-0.70464437, -0.61517552, -0.47654234],\n",
       "       [ 1.05031896,  1.20925106,  0.6235196 ],\n",
       "       [-0.48527395,  0.56330861, -0.47809703],\n",
       "       [-0.48527395,  1.20925106,  3.08461133],\n",
       "       [-0.92401479,  0.64999031, -0.48182536],\n",
       "       [-0.04653312,  1.20925106,  1.38170246],\n",
       "       [ 2.14717105, -0.73631974, -0.45625283],\n",
       "       [-1.1433852 ,  0.10029884, -0.45596728],\n",
       "       [ 0.1728373 ,  1.20788935, -0.43091537],\n",
       "       [ 0.61157813, -0.64801076, -0.46196708],\n",
       "       [-0.26590354,  0.18843143, -0.17451801],\n",
       "       [ 0.83094855, -0.24491726, -0.47731221],\n",
       "       [ 0.1728373 , -0.11025357, -0.43458602],\n",
       "       [-1.36275562,  1.20925106,  3.84714663],\n",
       "       [ 0.61157813, -0.36128586, -0.46703569],\n",
       "       [-1.58212603, -1.43291057, -0.47535143],\n",
       "       [-0.48527395, -1.17715167, -0.43039986],\n",
       "       [-0.92401479, -0.30932179, -0.43116225],\n",
       "       [ 1.4890598 ,  0.52858771, -0.47172892],\n",
       "       [-0.70464437, -0.03116808, -0.47919698],\n",
       "       [-0.48527395, -0.90623366, -0.48109268],\n",
       "       [ 0.39220771, -0.67600562, -0.46676964],\n",
       "       [-0.48527395,  1.20925106,  1.83059329],\n",
       "       [ 1.26968938,  0.38914824,  0.78833929],\n",
       "       [-1.80149645, -1.11807822, -0.47606336],\n",
       "       [-1.1433852 ,  1.20925106,  3.00108092],\n",
       "       [-0.26590354,  1.20925106,  2.28069712],\n",
       "       [-2.02086687, -1.28442855, -0.45667518],\n",
       "       [ 1.26968938,  1.20925106,  0.94629043],\n",
       "       [ 0.39220771, -1.19403994, -0.46285046],\n",
       "       [ 0.83094855,  1.20925106, -0.26078545],\n",
       "       [ 1.05031896, -1.42047971, -0.48151624],\n",
       "       [ 1.26968938, -1.39823367, -0.46808926],\n",
       "       [ 0.83094855,  0.21441272, -0.44868576],\n",
       "       [-0.26590354,  1.2061038 , -0.41392495],\n",
       "       [-2.02086687, -0.21234417, -0.46268477],\n",
       "       [-0.26590354,  1.20925106,  2.31698859],\n",
       "       [-0.04653312, -0.41164951, -0.46196173],\n",
       "       [-2.02086687, -1.01143152, -0.46838431],\n",
       "       [-0.04653312,  0.84007028, -0.45936937],\n",
       "       [-2.02086687, -1.42994102, -0.45803544],\n",
       "       [ 0.1728373 , -1.05688359, -0.13377141],\n",
       "       [-0.26590354,  0.79616067, -0.46829105],\n",
       "       [-0.92401479,  1.20641362, -0.35764503],\n",
       "       [ 0.39220771,  1.13926596,  0.90738859],\n",
       "       [ 0.39220771,  0.42759052, -0.46880499],\n",
       "       [-0.48527395, -0.69698833, -0.47328927],\n",
       "       [ 1.4890598 ,  1.04613416, -0.39518452],\n",
       "       [-0.04653312, -0.1774942 , -0.46633831],\n",
       "       [-0.48527395, -1.41996954, -0.47061087],\n",
       "       [-0.26590354, -0.76122491, -0.46358437],\n",
       "       [-0.48527395, -1.1514034 ,  1.92878331],\n",
       "       [ 0.1728373 , -0.87137681, -0.45613199],\n",
       "       [-0.92401479, -0.45070531, -0.48101185],\n",
       "       [-0.70464437,  0.68632817, -0.48317283],\n",
       "       [-0.92401479,  1.20842454,  4.27030597],\n",
       "       [-0.26590354, -1.41345202, -0.4614624 ],\n",
       "       [-0.26590354, -0.00813784, -0.4729993 ],\n",
       "       [ 0.83094855, -0.65250332, -0.48022141],\n",
       "       [ 0.61157813, -0.48621842, -0.30275354],\n",
       "       [-0.26590354,  0.72567136, -0.47926705],\n",
       "       [-0.92401479, -0.40681645, -0.48231624],\n",
       "       [ 0.83094855, -0.13123852, -0.47688968],\n",
       "       [-0.04653312,  0.38914824,  2.23645918],\n",
       "       [-0.04653312, -0.48907341, -0.47306854],\n",
       "       [ 0.1728373 , -0.40482323, -0.46607239],\n",
       "       [-0.26590354, -0.55739022, -0.47331907],\n",
       "       [ 0.61157813,  1.20925106,  1.37070706],\n",
       "       [ 1.92780063, -0.15741431, -0.4708046 ],\n",
       "       [ 1.26968938,  1.20925106, -0.23372383],\n",
       "       [ 0.1728373 , -0.86541974, -0.45275268],\n",
       "       [-0.48527395, -0.84897376, -0.47042357],\n",
       "       [-0.04653312,  0.04263802, -0.45827581],\n",
       "       [-1.36275562,  0.31864122, -0.44704813],\n",
       "       [ 0.1728373 , -1.34096172, -0.46991289],\n",
       "       [ 0.39220771,  1.20925106, -0.37541946],\n",
       "       [-0.04653312,  0.99862716, -0.47851933],\n",
       "       [-0.26590354,  1.18646122, -0.46448781],\n",
       "       [ 0.61157813,  1.0903611 , -0.4393795 ],\n",
       "       [ 0.1728373 , -0.86773682,  1.16279606],\n",
       "       [-1.36275562, -0.20846547, -0.47156573],\n",
       "       [-0.04653312, -0.29643281, -0.45936189],\n",
       "       [-0.48527395, -0.25503257, -0.4654093 ],\n",
       "       [-1.36275562, -0.10360894, -0.47544378],\n",
       "       [ 1.05031896, -0.42573244, -0.47060543],\n",
       "       [-1.36275562,  0.3438851 , -0.46159864],\n",
       "       [-1.36275562, -1.21425342, -0.4722799 ],\n",
       "       [-0.26590354, -0.64697129, -0.4767294 ],\n",
       "       [ 0.61157813, -1.41817976, -0.4640268 ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heavy-reducing",
   "metadata": {},
   "source": [
    "since the data in each dimension of X should be scaled similarly for the model, the below code rescales the features. This minimizes the the bias in which dimensioanlity can drastically favor closseness in arbitary dimensions of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "genuine-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "graduate-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83094855, -0.3309303 ,  0.88631636],\n",
       "       [-1.80149645, -1.43484657, -0.47215367],\n",
       "       [ 1.4890598 , -1.39066252, -0.45712038],\n",
       "       [ 0.83094855,  0.16504603, -0.4736127 ],\n",
       "       [-0.92401479, -0.21582207, -0.48093728],\n",
       "       [ 0.1728373 ,  0.66843307, -0.45730025],\n",
       "       [-0.04653312, -0.85260367, -0.48168787],\n",
       "       [-1.80149645,  0.0925481 , -0.48091341],\n",
       "       [-0.26590354, -0.82947756, -0.42197313],\n",
       "       [ 1.4890598 ,  1.20925106,  0.4871487 ],\n",
       "       [-0.04653312,  0.36801853, -0.4668838 ],\n",
       "       [ 1.05031896,  1.20925106, -0.15266484],\n",
       "       [ 0.61157813, -1.14343681,  0.83598965],\n",
       "       [-0.48527395, -1.39739706, -0.47726315],\n",
       "       [ 1.4890598 , -0.56317921,  0.44440965],\n",
       "       [ 0.61157813, -1.3874822 , -0.42591268],\n",
       "       [ 1.05031896, -0.56556129, -0.48113768],\n",
       "       [ 0.39220771, -0.0588771 , -0.47952282],\n",
       "       [ 0.83094855,  0.06022101, -0.4740099 ],\n",
       "       [ 1.26968938, -1.19078194,  0.8982723 ],\n",
       "       [-0.70464437,  1.20842454,  4.05802373],\n",
       "       [ 2.14717105,  0.14698322, -0.44157236],\n",
       "       [ 0.61157813, -0.2276639 , -0.42245002],\n",
       "       [ 0.83094855, -0.10316899, -0.47193229],\n",
       "       [-0.48527395, -1.14932964, -0.46780759],\n",
       "       [-1.58212603, -0.70024029, -0.46469502],\n",
       "       [-0.70464437,  1.18335365, -0.32070466],\n",
       "       [ 0.1728373 , -1.4126102 , -0.4690091 ],\n",
       "       [-0.26590354, -1.19036279, -0.28985651],\n",
       "       [ 1.70843021,  1.18830239, -0.38361572],\n",
       "       [ 0.1728373 ,  0.59698151, -0.47820425],\n",
       "       [ 1.05031896,  1.13071872,  1.09591091],\n",
       "       [ 1.05031896,  0.7789422 , -0.46190167],\n",
       "       [ 1.26968938,  1.20925106,  0.83492003],\n",
       "       [ 0.61157813,  0.8641519 , -0.46889603],\n",
       "       [-1.58212603, -0.76076791, -0.46555636],\n",
       "       [-0.04653312, -1.3004255 , -0.46141571],\n",
       "       [-0.04653312,  1.19900643, -0.27793947],\n",
       "       [-0.26590354, -1.17777256, -0.4639526 ],\n",
       "       [-0.92401479, -1.39574803, -0.46440767],\n",
       "       [-0.26590354,  0.21624914, -0.48620567],\n",
       "       [-1.36275562,  1.14187533, -0.47813089],\n",
       "       [ 0.39220771,  1.20925106,  1.60618038],\n",
       "       [ 0.83094855,  1.16508406, -0.43125083],\n",
       "       [-1.36275562, -0.5262775 , -0.47900298],\n",
       "       [-1.1433852 , -1.37534039, -0.45944724],\n",
       "       [ 1.05031896,  1.2052084 , -0.36917556],\n",
       "       [-0.04653312,  0.1282605 , -0.47782105],\n",
       "       [-0.48527395,  1.20925106,  1.72533205],\n",
       "       [-1.36275562, -0.77771523, -0.32882378],\n",
       "       [-0.92401479, -1.3905876 , -0.40458579],\n",
       "       [ 0.1728373 ,  0.22430795, -0.45657558],\n",
       "       [-0.92401479, -0.42615502, -0.46317393],\n",
       "       [-0.92401479, -1.14462495, -0.47541621],\n",
       "       [-1.58212603, -1.43484657, -0.45798432],\n",
       "       [-0.70464437,  1.20757309, -0.34582822],\n",
       "       [-0.48527395, -0.75522557, -0.46722557],\n",
       "       [-1.80149645, -1.43484657, -0.47628418],\n",
       "       [ 0.61157813,  1.2075027 , -0.30145313],\n",
       "       [-0.04653312, -1.42033835, -0.45644505],\n",
       "       [ 0.39220771,  0.24316216, -0.47829782],\n",
       "       [-0.04653312,  0.87392747, -0.46702941],\n",
       "       [-1.1433852 , -1.12013731, -0.46934476],\n",
       "       [ 0.39220771,  1.20925106,  1.42700596],\n",
       "       [-0.48527395,  1.20925106,  1.771634  ],\n",
       "       [-1.58212603,  0.45687289, -0.46213472],\n",
       "       [-0.48527395,  1.20925106, -0.32104367],\n",
       "       [ 1.4890598 ,  0.44894284, -0.42350579],\n",
       "       [ 0.61157813, -0.49386222, -0.46589848],\n",
       "       [ 1.05031896, -0.96301871, -0.46712416],\n",
       "       [-1.58212603, -0.36005375, -0.45417722],\n",
       "       [ 1.70843021,  1.13071872,  0.78878837],\n",
       "       [ 1.92780063, -0.35903058, -0.46872967],\n",
       "       [ 0.39220771,  1.20925106,  0.97602429],\n",
       "       [-0.04653312,  1.00219244, -0.47049167],\n",
       "       [-0.70464437,  1.20925102, -0.42085801],\n",
       "       [-0.48527395, -0.3529792 , -0.46592834],\n",
       "       [-0.04653312,  1.20925106, -0.28851355],\n",
       "       [-0.92401479,  0.63911995, -0.46967463],\n",
       "       [-2.02086687, -1.43484657, -0.45633772],\n",
       "       [ 0.39220771,  0.60554386, -0.44588278],\n",
       "       [ 0.61157813,  1.18547829, -0.43318111],\n",
       "       [-0.04653312, -0.61271224, -0.46675096],\n",
       "       [-0.26590354,  0.93573156, -0.44517818],\n",
       "       [ 1.70843021, -1.19078194,  0.31064111],\n",
       "       [ 1.05031896,  1.20925106, -0.19966644],\n",
       "       [ 0.61157813,  1.10899031, -0.4415573 ],\n",
       "       [-1.1433852 , -0.58365164, -0.4757137 ],\n",
       "       [-2.02086687, -1.43484657, -0.45693078],\n",
       "       [ 0.1728373 , -1.15322501, -0.47065466],\n",
       "       [-2.02086687, -1.42122864, -0.47111938],\n",
       "       [ 0.39220771, -0.61877414, -0.44920636],\n",
       "       [-0.04653312,  1.20739687, -0.3028198 ],\n",
       "       [-0.04653312,  1.20925106,  2.12311316],\n",
       "       [-0.70464437, -1.40056385, -0.47818209],\n",
       "       [ 1.26968938, -1.41268282, -0.48039939],\n",
       "       [-0.70464437,  0.38914824,  2.92120297],\n",
       "       [ 1.92780063,  1.20925106,  0.33540382],\n",
       "       [-0.04653312, -1.42708503, -0.46329271],\n",
       "       [-0.04653312,  0.6217074 , -0.45310529],\n",
       "       [ 0.39220771, -0.55105072, -0.47149271],\n",
       "       [ 0.83094855, -1.28683109, -0.46786528],\n",
       "       [ 0.1728373 , -0.78035146, -0.48195962],\n",
       "       [ 2.58591188,  1.19920521, -0.41844625],\n",
       "       [-2.02086687, -0.32339283, -0.45905325],\n",
       "       [ 1.4890598 ,  0.32168868, -0.47163846],\n",
       "       [ 1.4890598 , -0.56317921,  0.59146135],\n",
       "       [ 1.05031896,  1.20925106,  1.08656873],\n",
       "       [ 1.26968938,  0.54653848, -0.46848902],\n",
       "       [ 0.39220771, -1.42253781, -0.48143074],\n",
       "       [-1.58212603, -1.1400455 , -0.46945261],\n",
       "       [ 0.61157813, -1.42517215, -0.46166987],\n",
       "       [-2.02086687, -1.43484657, -0.43653934],\n",
       "       [ 0.1728373 ,  1.20925104, -0.38722496],\n",
       "       [-0.26590354,  0.05314477, -0.46607091],\n",
       "       [-0.92401479,  0.81141551, -0.48142805],\n",
       "       [-0.26590354,  1.20925106,  1.55300384],\n",
       "       [ 2.14717105, -1.28103212, -0.46906607],\n",
       "       [ 0.61157813,  0.56601517, -0.46987839],\n",
       "       [ 1.70843021,  1.20925106,  0.39861956],\n",
       "       [-0.04653312, -1.36993926, -0.47706155],\n",
       "       [ 1.92780063,  1.13071873,  0.73628173],\n",
       "       [ 2.58591188,  0.78054699, -0.40417891],\n",
       "       [ 0.1728373 , -0.1690762 , -0.47974364],\n",
       "       [-0.26590354,  1.16488368, -0.46793205],\n",
       "       [-0.26590354, -1.41475244, -0.47901379],\n",
       "       [-0.48527395, -0.80037796, -0.46648321],\n",
       "       [ 1.70843021, -0.0193118 , -0.45783022],\n",
       "       [ 3.02465271, -1.40584374, -0.4639375 ],\n",
       "       [ 0.61157813, -1.40945263, -0.442079  ],\n",
       "       [ 0.83094855,  1.20750777, -0.33891018],\n",
       "       [-0.48527395, -0.19388311, -0.46628308],\n",
       "       [ 1.4890598 ,  1.20925106,  0.48415684],\n",
       "       [ 0.39220771,  1.20925106,  1.04856964],\n",
       "       [-1.1433852 ,  1.20925106,  3.25963881],\n",
       "       [-1.36275562, -1.38444307, -0.45488785],\n",
       "       [-1.58212603, -1.42926274, -0.47316808],\n",
       "       [-1.1433852 , -1.42070679, -0.46779305],\n",
       "       [ 0.61157813,  1.16816169, -0.44088421],\n",
       "       [-0.92401479, -0.84614667, -0.44566789],\n",
       "       [-1.1433852 , -0.11402971, -0.47585265],\n",
       "       [-0.04653312,  1.20925106,  1.29993232],\n",
       "       [ 0.39220771,  1.20925106,  1.53627466],\n",
       "       [-0.26590354,  1.20740651, -0.26581253],\n",
       "       [ 0.1728373 ,  1.20925106,  1.06372476],\n",
       "       [-0.92401479,  1.20687811, -0.30301186],\n",
       "       [-1.80149645, -0.96413206, -0.46686834],\n",
       "       [-0.26590354,  1.20925106,  1.52084743],\n",
       "       [ 1.05031896,  1.20925106,  0.64943395],\n",
       "       [-0.92401479,  1.20842454,  4.29363386],\n",
       "       [-0.70464437,  1.20925106,  2.08780698],\n",
       "       [-0.92401479,  1.20925106,  2.58573946],\n",
       "       [ 0.39220771,  0.197937  , -0.46209362],\n",
       "       [-0.92401479, -1.10508786, -0.39796064],\n",
       "       [ 0.39220771,  0.81156355, -0.45160495],\n",
       "       [ 1.26968938,  1.19511243, -0.4657902 ],\n",
       "       [-1.36275562, -1.43484657, -0.45610855],\n",
       "       [ 0.83094855, -1.20882747, -0.47108607],\n",
       "       [-0.04653312,  0.60670685, -0.47131335],\n",
       "       [-0.04653312, -1.39045832, -0.46272115],\n",
       "       [-0.04653312, -1.20699629, -0.45996572],\n",
       "       [-0.92401479, -0.07385026, -0.4754846 ],\n",
       "       [ 1.05031896,  0.41020988, -0.42829326],\n",
       "       [-1.1433852 , -1.00763342, -0.47615313],\n",
       "       [ 0.61157813,  0.28508695, -0.46846838],\n",
       "       [-0.92401479, -1.42895433, -0.45612641],\n",
       "       [ 1.05031896,  1.04052859, -0.44129454],\n",
       "       [-1.1433852 ,  1.13789511, -0.45330328],\n",
       "       [ 1.26968938, -1.38815749, -0.46633645],\n",
       "       [ 1.05031896,  0.5031881 , -0.46203118],\n",
       "       [ 0.39220771, -1.24236706, -0.47190365],\n",
       "       [-0.26590354, -1.20071561, -0.41729372],\n",
       "       [ 0.83094855, -0.24248916, -0.43004575],\n",
       "       [-0.26590354,  1.20925106,  1.52815925],\n",
       "       [-0.26590354,  1.2090329 , -0.36711671],\n",
       "       [ 1.26968938,  1.20740651, -0.38563272],\n",
       "       [-0.70464437, -0.52114642, -0.45393035],\n",
       "       [ 0.39220771, -1.35751641, -0.47923624],\n",
       "       [ 1.70843021, -1.19078194,  0.31591215],\n",
       "       [-0.26590354, -1.2141341 , -0.47541087],\n",
       "       [-0.26590354,  0.73975174, -0.47379676],\n",
       "       [-0.04653312,  1.20925106,  2.11083059],\n",
       "       [-0.26590354,  1.20925106,  2.23807322],\n",
       "       [ 0.1728373 ,  1.20711316, -0.21482872],\n",
       "       [ 1.26968938,  0.39737486, -0.42173412],\n",
       "       [-0.26590354, -0.07382758, -0.46300553],\n",
       "       [ 1.05031896,  0.98540838, -0.47173259],\n",
       "       [ 1.70843021, -0.50989775, -0.44424521],\n",
       "       [ 0.1728373 , -1.15209734, -0.4058084 ],\n",
       "       [ 0.39220771,  1.20925106, -0.22874915],\n",
       "       [-1.1433852 , -1.07561701,  3.30406663],\n",
       "       [ 0.61157813, -1.39237934, -0.48186253],\n",
       "       [-1.80149645,  0.18772675, -0.44827493],\n",
       "       [ 0.83094855,  1.19009082, -0.45678975],\n",
       "       [-0.48527395, -1.07052019, -0.47487409],\n",
       "       [ 0.1728373 ,  0.39460748, -0.45432732],\n",
       "       [-0.92401479, -0.20665224, -0.46596474],\n",
       "       [ 0.1728373 ,  1.20925106,  1.86666645],\n",
       "       [ 0.61157813,  1.20925106, -0.36960672],\n",
       "       [-0.48527395, -1.1514034 ,  2.019383  ],\n",
       "       [ 1.05031896,  1.20925106,  1.03110868],\n",
       "       [ 0.39220771,  0.97409434, -0.47897857],\n",
       "       [-0.48527395, -1.41956653, -0.47932674],\n",
       "       [-0.70464437,  1.20842454,  4.10136565],\n",
       "       [-0.70464437,  1.20925106,  2.08686876],\n",
       "       [ 0.1728373 , -1.41985271, -0.45254294],\n",
       "       [ 0.61157813,  0.73995681, -0.42741027],\n",
       "       [-1.36275562,  1.20925106,  3.84610713],\n",
       "       [-0.70464437, -0.61517552, -0.47654234],\n",
       "       [ 1.05031896,  1.20925106,  0.6235196 ],\n",
       "       [-0.48527395,  0.56330861, -0.47809703],\n",
       "       [-0.48527395,  1.20925106,  3.08461133],\n",
       "       [-0.92401479,  0.64999031, -0.48182536],\n",
       "       [-0.04653312,  1.20925106,  1.38170246],\n",
       "       [ 2.14717105, -0.73631974, -0.45625283],\n",
       "       [-1.1433852 ,  0.10029884, -0.45596728],\n",
       "       [ 0.1728373 ,  1.20788935, -0.43091537],\n",
       "       [ 0.61157813, -0.64801076, -0.46196708],\n",
       "       [-0.26590354,  0.18843143, -0.17451801],\n",
       "       [ 0.83094855, -0.24491726, -0.47731221],\n",
       "       [ 0.1728373 , -0.11025357, -0.43458602],\n",
       "       [-1.36275562,  1.20925106,  3.84714663],\n",
       "       [ 0.61157813, -0.36128586, -0.46703569],\n",
       "       [-1.58212603, -1.43291057, -0.47535143],\n",
       "       [-0.48527395, -1.17715167, -0.43039986],\n",
       "       [-0.92401479, -0.30932179, -0.43116225],\n",
       "       [ 1.4890598 ,  0.52858771, -0.47172892],\n",
       "       [-0.70464437, -0.03116808, -0.47919698],\n",
       "       [-0.48527395, -0.90623366, -0.48109268],\n",
       "       [ 0.39220771, -0.67600562, -0.46676964],\n",
       "       [-0.48527395,  1.20925106,  1.83059329],\n",
       "       [ 1.26968938,  0.38914824,  0.78833929],\n",
       "       [-1.80149645, -1.11807822, -0.47606336],\n",
       "       [-1.1433852 ,  1.20925106,  3.00108092],\n",
       "       [-0.26590354,  1.20925106,  2.28069712],\n",
       "       [-2.02086687, -1.28442855, -0.45667518],\n",
       "       [ 1.26968938,  1.20925106,  0.94629043],\n",
       "       [ 0.39220771, -1.19403994, -0.46285046],\n",
       "       [ 0.83094855,  1.20925106, -0.26078545],\n",
       "       [ 1.05031896, -1.42047971, -0.48151624],\n",
       "       [ 1.26968938, -1.39823367, -0.46808926],\n",
       "       [ 0.83094855,  0.21441272, -0.44868576],\n",
       "       [-0.26590354,  1.2061038 , -0.41392495],\n",
       "       [-2.02086687, -0.21234417, -0.46268477],\n",
       "       [-0.26590354,  1.20925106,  2.31698859],\n",
       "       [-0.04653312, -0.41164951, -0.46196173],\n",
       "       [-2.02086687, -1.01143152, -0.46838431],\n",
       "       [-0.04653312,  0.84007028, -0.45936937],\n",
       "       [-2.02086687, -1.42994102, -0.45803544],\n",
       "       [ 0.1728373 , -1.05688359, -0.13377141],\n",
       "       [-0.26590354,  0.79616067, -0.46829105],\n",
       "       [-0.92401479,  1.20641362, -0.35764503],\n",
       "       [ 0.39220771,  1.13926596,  0.90738859],\n",
       "       [ 0.39220771,  0.42759052, -0.46880499],\n",
       "       [-0.48527395, -0.69698833, -0.47328927],\n",
       "       [ 1.4890598 ,  1.04613416, -0.39518452],\n",
       "       [-0.04653312, -0.1774942 , -0.46633831],\n",
       "       [-0.48527395, -1.41996954, -0.47061087],\n",
       "       [-0.26590354, -0.76122491, -0.46358437],\n",
       "       [-0.48527395, -1.1514034 ,  1.92878331],\n",
       "       [ 0.1728373 , -0.87137681, -0.45613199],\n",
       "       [-0.92401479, -0.45070531, -0.48101185],\n",
       "       [-0.70464437,  0.68632817, -0.48317283],\n",
       "       [-0.92401479,  1.20842454,  4.27030597],\n",
       "       [-0.26590354, -1.41345202, -0.4614624 ],\n",
       "       [-0.26590354, -0.00813784, -0.4729993 ],\n",
       "       [ 0.83094855, -0.65250332, -0.48022141],\n",
       "       [ 0.61157813, -0.48621842, -0.30275354],\n",
       "       [-0.26590354,  0.72567136, -0.47926705],\n",
       "       [-0.92401479, -0.40681645, -0.48231624],\n",
       "       [ 0.83094855, -0.13123852, -0.47688968],\n",
       "       [-0.04653312,  0.38914824,  2.23645918],\n",
       "       [-0.04653312, -0.48907341, -0.47306854],\n",
       "       [ 0.1728373 , -0.40482323, -0.46607239],\n",
       "       [-0.26590354, -0.55739022, -0.47331907],\n",
       "       [ 0.61157813,  1.20925106,  1.37070706],\n",
       "       [ 1.92780063, -0.15741431, -0.4708046 ],\n",
       "       [ 1.26968938,  1.20925106, -0.23372383],\n",
       "       [ 0.1728373 , -0.86541974, -0.45275268],\n",
       "       [-0.48527395, -0.84897376, -0.47042357],\n",
       "       [-0.04653312,  0.04263802, -0.45827581],\n",
       "       [-1.36275562,  0.31864122, -0.44704813],\n",
       "       [ 0.1728373 , -1.34096172, -0.46991289],\n",
       "       [ 0.39220771,  1.20925106, -0.37541946],\n",
       "       [-0.04653312,  0.99862716, -0.47851933],\n",
       "       [-0.26590354,  1.18646122, -0.46448781],\n",
       "       [ 0.61157813,  1.0903611 , -0.4393795 ],\n",
       "       [ 0.1728373 , -0.86773682,  1.16279606],\n",
       "       [-1.36275562, -0.20846547, -0.47156573],\n",
       "       [-0.04653312, -0.29643281, -0.45936189],\n",
       "       [-0.48527395, -0.25503257, -0.4654093 ],\n",
       "       [-1.36275562, -0.10360894, -0.47544378],\n",
       "       [ 1.05031896, -0.42573244, -0.47060543],\n",
       "       [-1.36275562,  0.3438851 , -0.46159864],\n",
       "       [-1.36275562, -1.21425342, -0.4722799 ],\n",
       "       [-0.26590354, -0.64697129, -0.4767294 ],\n",
       "       [ 0.61157813, -1.41817976, -0.4640268 ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "alive-stations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1., 170., 105., 108.,  94.,  86.,  79., 103.,  54., 384.]),\n",
       " array([-1.93485269, -1.62176677, -1.30868084, -0.99559492, -0.68250899,\n",
       "        -0.36942306, -0.05633714,  0.25674879,  0.56983472,  0.88292064,\n",
       "         1.19600657]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "medical-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_neighbors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "removed-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2, weights='distance')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the model: Init K-NN\n",
    "# We create an instance of Neighbours Classifier and fit it to the training data.\n",
    "# if you set weights = 'distance' here you will have a weighted KNN classifier\n",
    "clf = neighbors.KNeighborsClassifier(K_neighbors, weights='distance')\n",
    "\n",
    "# Here we fit it to the data - it figures out the assigned_classes and \n",
    "# which training X points belong to each class in Y \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "based-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] euclidean 1184\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_, clf.effective_metric_, clf.n_samples_fit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "adverse-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted classes [4 3 1 1 3 0 1 2 1 4 2 0 4 0 4 1 2 1 2 4 4 1 2 1 3 1 0 1 0 0 2 4 1 4 3 3 1\n",
      " 0 0 1 3 3 4 3 1 1 0 2 4 0 1 2 0 3 3 0 2 3 0 3 2 1 2 4 4 0 0 1 1 1 3 4 0 4\n",
      " 2 0 3 0 2 3 2 0 2 2 4 0 3 2 3 2 3 2 0 4 2 1 4 4 3 1 3 1 0 3 2 2 4 4 2 2 2\n",
      " 2 3 0 3 3 4 2 1 4 2 4 3 2 3 0 3 2 3 2 0 3 4 4 4 0 3 1 0 3 1 4 4 0 4 0 1 4\n",
      " 4 4 4 4 1 2 2 1 1 0 1 3 2 3 1 2 3 1 2 3 1 1 0 0 1 4 0 3 3 0 4 0 3 4 4 0 2\n",
      " 3 2 2 1 0 4 2 2 3 3 3 3 4 0 4 4 1 2 4 4 1 3 4 2 4 2 4 2 4 1 1 0 1 1 1 2 4\n",
      " 1 3 1 3 2 3 2 0 4 4 1 4 4 3 4 0 0 2 1 2 0 2 4 2 2 1 3 0 3 0 4 2 2 3 2 2 3\n",
      " 4 2 0 0 4 0 1 2 3 3 0 1 4 1 1 1 4 2 0 2 2 2 2 1 0 2 0 3 4 1 3 3 3 1 2 3 2\n",
      " 2]\n",
      "KNN probability of belonging to class [[0.         0.         0.         0.         1.        ]\n",
      " [0.         0.48378324 0.         0.51621676 0.        ]\n",
      " [0.         1.         0.         0.         0.        ]\n",
      " ...\n",
      " [0.37307925 0.         0.         0.62692075 0.        ]\n",
      " [0.         0.         1.         0.         0.        ]\n",
      " [0.         0.46702857 0.53297143 0.         0.        ]]\n",
      "Mean accuracy of prediction 0.5218855218855218\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set results\n",
    "y_test_predicted = clf.predict(X_test)\n",
    "y_test_probabilities = clf.predict_proba(X_test)\n",
    "mean_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"predicted classes\", y_test_predicted)\n",
    "print(\"KNN probability of belonging to class\",y_test_probabilities)\n",
    "print(\"Mean accuracy of prediction\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "extended-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.367003367003367"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "coupled-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337    4\n",
       "1012    3\n",
       "1096    1\n",
       "990     2\n",
       "712     3\n",
       "       ..\n",
       "790     1\n",
       "307     1\n",
       "198     0\n",
       "747     3\n",
       "1098    1\n",
       "Name: assigned_class, Length: 297, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "processed-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2, 1, 1, 2, 0, 1, 4, 3, 3, 2, 4, 0, 1, 0, 4, 4, 1, 2,\n",
       "       4, 4, 0, 4, 1, 2, 1, 4, 2, 4, 4, 0, 2, 2, 0, 1, 1, 4, 4, 0, 0, 1,\n",
       "       4, 4, 2, 1, 1, 4, 4, 1, 0, 2, 1, 0, 0, 2, 2, 3, 3, 2, 4, 2, 4, 2,\n",
       "       2, 0, 2, 2, 3, 2, 3, 2, 3, 4, 3, 0, 2, 4, 0, 1, 1, 0, 2, 2, 1, 3,\n",
       "       1, 2, 2, 0, 4, 2, 0, 0, 4, 3, 2, 1, 3, 3, 1, 4, 0, 3, 2, 2, 4, 2,\n",
       "       2, 1, 4, 4, 1, 0, 2, 2, 3, 0, 3, 3, 1, 1, 3, 4, 3, 2, 2, 0, 3, 3,\n",
       "       1, 4, 3, 1, 1, 0, 0, 4, 3, 4, 4, 4, 1, 1, 2, 3, 1, 4, 4, 0, 2, 4,\n",
       "       4, 1, 1, 3, 2, 0, 3, 1, 2, 3, 4, 4, 0, 3, 4, 2, 0, 4, 4, 2, 3, 3,\n",
       "       1, 1, 4, 0, 4, 3, 4, 3, 2, 2, 0, 2, 0, 3, 2, 3, 1, 4, 4, 2, 4, 4,\n",
       "       0, 1, 4, 1, 4, 1, 4, 3, 1, 0, 3, 4, 4, 4, 3, 2, 3, 1, 4, 0, 1, 3,\n",
       "       4, 1, 0, 3, 2, 3, 1, 2, 4, 0, 2, 2, 3, 4, 1, 3, 2, 1, 3, 1, 3, 3,\n",
       "       0, 2, 4, 2, 1, 3, 0, 0, 1, 3, 4, 2, 1, 2, 2, 1, 2, 0, 2, 3, 4, 2,\n",
       "       1, 1, 4, 4, 0, 0, 1, 3, 3, 4, 3, 2, 3, 1, 2, 1, 0, 3, 3, 1, 3, 2,\n",
       "       2, 4, 2, 4, 0, 4, 3, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "removable-arlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3748442 ,  0.22210381, -0.7000885 , ..., -0.46954042,\n",
       "        0.22210381, -0.23899234])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-breath",
   "metadata": {},
   "source": [
    "A confusion matrix is a matrix that can be used to measure the performance of a machine learning algorithm. Each row of the matrix represents the instances of an actual assigned_class and each column represents the instances of a predicted class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "meaning-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  6  3  5  0  0]\n",
      " [ 3 24 13  8  0  0]\n",
      " [ 3 14 29  9  0  0]\n",
      " [ 8 16 21 34  0  0]\n",
      " [ 0  0  0  0 67  0]\n",
      " [ 0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "cm = confusion_matrix(y_test, y_test_predicted, labels=[0,1,2,3,4,5])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-vector",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "greenhouse-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    \"\"\"Precision is the fraction of cases where the algorith correctly predicted assigned_class \n",
    "       out of all instances where the algorithm predicted (correctly and incorrectly)\"\"\"\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "\n",
    "def recall(label, confusion_matrix):\n",
    "    \"\"\"recall is the fraction of cases where the algorithm correctly predicted out of all of \n",
    "       the cases which are labelled as a specific assigned_class\"\"\"\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    \"\"\"calculates the precision for the whole classification problem calculates\"\"\"\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    \"\"\"calculates the recall for the whole classification problem calculates\"\"\"\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "authentic-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label precision recall\n",
      "    0     0.689  0.689\n",
      "    1     0.400  0.500\n",
      "    2     0.439  0.527\n",
      "    3     0.607  0.430\n",
      "    4     1.000  1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"label precision recall\")\n",
    "for label in range(5):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cross-mount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision total: nan\n",
      "recall total: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-2c3491609826>:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  return confusion_matrix[label, label] / col.sum()\n",
      "<ipython-input-28-2c3491609826>:11: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  return confusion_matrix[label, label] / row.sum()\n"
     ]
    }
   ],
   "source": [
    "print(\"precision total:\", precision_macro_average(cm))\n",
    "\n",
    "print(\"recall total:\", recall_macro_average(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "capital-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6292517006802721"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-copying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "shaped-prediction",
   "metadata": {},
   "source": [
    "Support vector Machine (SVM) algorithm creates a line or a hyperplace which separates the data into classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "increased-selling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401360544217688"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear',C=1000,gamma='auto')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test, y_test)\n",
    "y_1_test_predicted = model.predict(X_test)\n",
    "sklearn.metrics.mean_squared_error(y_test, y_1_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "computational-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904761904761905"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-imagination",
   "metadata": {},
   "source": [
    "Hyper parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "forward-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': 0.4707645515544101,\n",
       " 'rbf_10': 0.49120986278470424,\n",
       " 'rbf_20': 0.4796080889693761,\n",
       " 'rbf_30': 0.4884609133755891,\n",
       " 'rbf_40': 0.4911750365675281,\n",
       " 'rbf_50': 0.49185995217199513,\n",
       " 'rbf_60': 0.4932274616331174,\n",
       " 'rbf_70': 0.49799168814283395,\n",
       " 'rbf_80': 0.4986719602516775,\n",
       " 'rbf_90': 0.5041164588702375,\n",
       " 'rbf_100': 0.5007011678391493,\n",
       " 'linear_1': 0.46736319101019247,\n",
       " 'linear_10': 0.5211511225650669,\n",
       " 'linear_20': 0.5490562095145226,\n",
       " 'linear_30': 0.5517772979498966,\n",
       " 'linear_40': 0.5531401639153956,\n",
       " 'linear_50': 0.5619837013303616,\n",
       " 'linear_60': 0.5633558542871074,\n",
       " 'linear_70': 0.5749228018852592,\n",
       " 'linear_80': 0.5803649787560075,\n",
       " 'linear_90': 0.5796800631515405,\n",
       " 'linear_100': 0.5864874277355995}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = ['rbf','linear']\n",
    "C = [1,10,20,30,40,50,60,70,80,90,100]\n",
    "avg_scores = {}\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(svm.SVC(kernel=kval,C=cval,gamma='auto'), X, df['type_of_opt'], cv=5)\n",
    "        avg_scores[kval + '_' + str(cval)] = np.average(cv_scores)\n",
    "        \n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-bankruptcy",
   "metadata": {},
   "source": [
    "Hyper parameter Tunning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "heavy-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0670301 , 0.07695694, 0.06339588, 0.21116834, 0.06416755,\n",
       "        0.40000749, 0.05977755, 0.53587461, 0.05952482, 0.7147656 ,\n",
       "        0.0700748 , 0.94798384, 0.06539345, 1.03993635, 0.06885319,\n",
       "        1.11897573, 0.06306458, 1.21781158, 0.06415677, 1.42717524,\n",
       "        0.06805382, 1.54982414]),\n",
       " 'std_fit_time': array([0.00829369, 0.00406045, 0.00414825, 0.02485756, 0.00371903,\n",
       "        0.05029138, 0.00182072, 0.12525131, 0.00185601, 0.10883252,\n",
       "        0.00229744, 0.18999281, 0.00211907, 0.20552263, 0.00636833,\n",
       "        0.14634032, 0.00293338, 0.19424037, 0.0031382 , 0.27325452,\n",
       "        0.00457902, 0.21493318]),\n",
       " 'mean_score_time': array([0.02878933, 0.00897884, 0.02654076, 0.0078825 , 0.02630239,\n",
       "        0.00734987, 0.02297311, 0.00708542, 0.02278509, 0.0080822 ,\n",
       "        0.02668338, 0.00742621, 0.02418451, 0.00719843, 0.02428679,\n",
       "        0.00704541, 0.02245688, 0.00684943, 0.02285438, 0.00735846,\n",
       "        0.02286701, 0.00691419]),\n",
       " 'std_score_time': array([2.40428700e-03, 7.12471869e-04, 1.19247536e-03, 5.52030830e-04,\n",
       "        2.36394133e-03, 7.10849862e-05, 5.29271362e-04, 2.16337745e-04,\n",
       "        4.06308200e-04, 8.23956623e-04, 8.04708704e-04, 1.09166701e-03,\n",
       "        1.89690888e-03, 4.92650665e-04, 2.43270044e-03, 1.39026500e-04,\n",
       "        6.95705250e-05, 8.79074358e-05, 1.11185841e-03, 8.33481135e-04,\n",
       "        5.38502643e-04, 1.58740830e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60,\n",
       "                    70, 70, 80, 80, 90, 90, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'},\n",
       "  {'C': 30, 'kernel': 'rbf'},\n",
       "  {'C': 30, 'kernel': 'linear'},\n",
       "  {'C': 40, 'kernel': 'rbf'},\n",
       "  {'C': 40, 'kernel': 'linear'},\n",
       "  {'C': 50, 'kernel': 'rbf'},\n",
       "  {'C': 50, 'kernel': 'linear'},\n",
       "  {'C': 60, 'kernel': 'rbf'},\n",
       "  {'C': 60, 'kernel': 'linear'},\n",
       "  {'C': 70, 'kernel': 'rbf'},\n",
       "  {'C': 70, 'kernel': 'linear'},\n",
       "  {'C': 80, 'kernel': 'rbf'},\n",
       "  {'C': 80, 'kernel': 'linear'},\n",
       "  {'C': 90, 'kernel': 'rbf'},\n",
       "  {'C': 90, 'kernel': 'linear'},\n",
       "  {'C': 100, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.39455782, 0.35714286, 0.39455782, 0.43197279, 0.39795918,\n",
       "        0.51020408, 0.40136054, 0.52721088, 0.41836735, 0.52040816,\n",
       "        0.40816327, 0.5170068 , 0.42176871, 0.5170068 , 0.42517007,\n",
       "        0.53741497, 0.43197279, 0.54421769, 0.44557823, 0.54081633,\n",
       "        0.44897959, 0.55442177]),\n",
       " 'split1_test_score': array([0.45238095, 0.44217687, 0.48639456, 0.51360544, 0.48639456,\n",
       "        0.55442177, 0.49319728, 0.55782313, 0.50340136, 0.56122449,\n",
       "        0.51020408, 0.59183673, 0.5170068 , 0.58503401, 0.52721088,\n",
       "        0.6122449 , 0.52721088, 0.62244898, 0.52721088, 0.62585034,\n",
       "        0.52380952, 0.63265306]),\n",
       " 'split2_test_score': array([0.4829932 , 0.51360544, 0.49659864, 0.56802721, 0.48979592,\n",
       "        0.56802721, 0.51020408, 0.56122449, 0.50680272, 0.56802721,\n",
       "        0.50680272, 0.58503401, 0.4829932 , 0.58163265, 0.48979592,\n",
       "        0.58843537, 0.48639456, 0.59863946, 0.49659864, 0.60204082,\n",
       "        0.5       , 0.60884354]),\n",
       " 'split3_test_score': array([0.51877133, 0.51877133, 0.54266212, 0.54948805, 0.52901024,\n",
       "        0.55972696, 0.53924915, 0.55972696, 0.53242321, 0.55972696,\n",
       "        0.53583618, 0.55972696, 0.54607509, 0.56996587, 0.54607509,\n",
       "        0.57679181, 0.54607509, 0.57679181, 0.54948805, 0.56996587,\n",
       "        0.52901024, 0.58020478]),\n",
       " 'split4_test_score': array([0.50511945, 0.50511945, 0.53583618, 0.54266212, 0.49488055,\n",
       "        0.55290102, 0.49829352, 0.55290102, 0.49488055, 0.55631399,\n",
       "        0.49829352, 0.55631399, 0.49829352, 0.56313993, 0.50170648,\n",
       "        0.55972696, 0.50170648, 0.55972696, 0.50170648, 0.55972696,\n",
       "        0.50170648, 0.55631399]),\n",
       " 'mean_test_score': array([0.47076455, 0.46736319, 0.49120986, 0.52115112, 0.47960809,\n",
       "        0.54905621, 0.48846091, 0.5517773 , 0.49117504, 0.55314016,\n",
       "        0.49185995, 0.5619837 , 0.49322746, 0.56335585, 0.49799169,\n",
       "        0.5749228 , 0.49867196, 0.58036498, 0.50411646, 0.57968006,\n",
       "        0.50070117, 0.58648743]),\n",
       " 'std_test_score': array([0.0442264 , 0.06162719, 0.05297676, 0.04790153, 0.04356653,\n",
       "        0.02013367, 0.04638491, 0.01259976, 0.03849626, 0.01680371,\n",
       "        0.04368118, 0.02639197, 0.04146103, 0.02447839, 0.0413515 ,\n",
       "        0.02536444, 0.03916695, 0.0277501 , 0.03487401, 0.03044529,\n",
       "        0.02832675, 0.03036174]),\n",
       " 'rank_test_score': array([21, 22, 17, 10, 20,  9, 19,  8, 18,  7, 16,  6, 15,  5, 14,  4, 13,\n",
       "         2, 11,  3, 12,  1], dtype=int32)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1,10,20,30,40,50,60,70,80,90,100],\n",
    "    'kernel':['rbf','linear']\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "clf.fit(X,df['type_of_opt'])\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "framed-hormone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.394558</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.482993</td>\n",
       "      <td>0.518771</td>\n",
       "      <td>0.505119</td>\n",
       "      <td>0.470765</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076957</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.513605</td>\n",
       "      <td>0.518771</td>\n",
       "      <td>0.505119</td>\n",
       "      <td>0.467363</td>\n",
       "      <td>0.061627</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.394558</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.535836</td>\n",
       "      <td>0.491210</td>\n",
       "      <td>0.052977</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211168</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.431973</td>\n",
       "      <td>0.513605</td>\n",
       "      <td>0.568027</td>\n",
       "      <td>0.549488</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.521151</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064168</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.529010</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.479608</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.400007</td>\n",
       "      <td>0.050291</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.554422</td>\n",
       "      <td>0.568027</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.552901</td>\n",
       "      <td>0.549056</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 30, 'kernel': 'rbf'}</td>\n",
       "      <td>0.401361</td>\n",
       "      <td>0.493197</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.539249</td>\n",
       "      <td>0.498294</td>\n",
       "      <td>0.488461</td>\n",
       "      <td>0.046385</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.535875</td>\n",
       "      <td>0.125251</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>30</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 30, 'kernel': 'linear'}</td>\n",
       "      <td>0.527211</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.552901</td>\n",
       "      <td>0.551777</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059525</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>40</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 40, 'kernel': 'rbf'}</td>\n",
       "      <td>0.418367</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>0.506803</td>\n",
       "      <td>0.532423</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.491175</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.714766</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>40</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 40, 'kernel': 'linear'}</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.568027</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.553140</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070075</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.026683</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'kernel': 'rbf'}</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.506803</td>\n",
       "      <td>0.535836</td>\n",
       "      <td>0.498294</td>\n",
       "      <td>0.491860</td>\n",
       "      <td>0.043681</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.947984</td>\n",
       "      <td>0.189993</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 50, 'kernel': 'linear'}</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.561984</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>60</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 60, 'kernel': 'rbf'}</td>\n",
       "      <td>0.421769</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.482993</td>\n",
       "      <td>0.546075</td>\n",
       "      <td>0.498294</td>\n",
       "      <td>0.493227</td>\n",
       "      <td>0.041461</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.039936</td>\n",
       "      <td>0.205523</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>60</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 60, 'kernel': 'linear'}</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>0.585034</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.569966</td>\n",
       "      <td>0.563140</td>\n",
       "      <td>0.563356</td>\n",
       "      <td>0.024478</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.068853</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>70</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 70, 'kernel': 'rbf'}</td>\n",
       "      <td>0.425170</td>\n",
       "      <td>0.527211</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.546075</td>\n",
       "      <td>0.501706</td>\n",
       "      <td>0.497992</td>\n",
       "      <td>0.041352</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.118976</td>\n",
       "      <td>0.146340</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>70</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 70, 'kernel': 'linear'}</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.588435</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.574923</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.063065</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>80</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 80, 'kernel': 'rbf'}</td>\n",
       "      <td>0.431973</td>\n",
       "      <td>0.527211</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>0.546075</td>\n",
       "      <td>0.501706</td>\n",
       "      <td>0.498672</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.217812</td>\n",
       "      <td>0.194240</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 80, 'kernel': 'linear'}</td>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.598639</td>\n",
       "      <td>0.576792</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.580365</td>\n",
       "      <td>0.027750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>90</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 90, 'kernel': 'rbf'}</td>\n",
       "      <td>0.445578</td>\n",
       "      <td>0.527211</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.549488</td>\n",
       "      <td>0.501706</td>\n",
       "      <td>0.504116</td>\n",
       "      <td>0.034874</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.427175</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>90</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 90, 'kernel': 'linear'}</td>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.569966</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.579680</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.068054</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.022867</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.529010</td>\n",
       "      <td>0.501706</td>\n",
       "      <td>0.500701</td>\n",
       "      <td>0.028327</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.549824</td>\n",
       "      <td>0.214933</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.554422</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.608844</td>\n",
       "      <td>0.580205</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.586487</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.067030      0.008294         0.028789        0.002404       1   \n",
       "1        0.076957      0.004060         0.008979        0.000712       1   \n",
       "2        0.063396      0.004148         0.026541        0.001192      10   \n",
       "3        0.211168      0.024858         0.007882        0.000552      10   \n",
       "4        0.064168      0.003719         0.026302        0.002364      20   \n",
       "5        0.400007      0.050291         0.007350        0.000071      20   \n",
       "6        0.059778      0.001821         0.022973        0.000529      30   \n",
       "7        0.535875      0.125251         0.007085        0.000216      30   \n",
       "8        0.059525      0.001856         0.022785        0.000406      40   \n",
       "9        0.714766      0.108833         0.008082        0.000824      40   \n",
       "10       0.070075      0.002297         0.026683        0.000805      50   \n",
       "11       0.947984      0.189993         0.007426        0.001092      50   \n",
       "12       0.065393      0.002119         0.024185        0.001897      60   \n",
       "13       1.039936      0.205523         0.007198        0.000493      60   \n",
       "14       0.068853      0.006368         0.024287        0.002433      70   \n",
       "15       1.118976      0.146340         0.007045        0.000139      70   \n",
       "16       0.063065      0.002933         0.022457        0.000070      80   \n",
       "17       1.217812      0.194240         0.006849        0.000088      80   \n",
       "18       0.064157      0.003138         0.022854        0.001112      90   \n",
       "19       1.427175      0.273255         0.007358        0.000833      90   \n",
       "20       0.068054      0.004579         0.022867        0.000539     100   \n",
       "21       1.549824      0.214933         0.006914        0.000159     100   \n",
       "\n",
       "   param_kernel                          params  split0_test_score  \\\n",
       "0           rbf       {'C': 1, 'kernel': 'rbf'}           0.394558   \n",
       "1        linear    {'C': 1, 'kernel': 'linear'}           0.357143   \n",
       "2           rbf      {'C': 10, 'kernel': 'rbf'}           0.394558   \n",
       "3        linear   {'C': 10, 'kernel': 'linear'}           0.431973   \n",
       "4           rbf      {'C': 20, 'kernel': 'rbf'}           0.397959   \n",
       "5        linear   {'C': 20, 'kernel': 'linear'}           0.510204   \n",
       "6           rbf      {'C': 30, 'kernel': 'rbf'}           0.401361   \n",
       "7        linear   {'C': 30, 'kernel': 'linear'}           0.527211   \n",
       "8           rbf      {'C': 40, 'kernel': 'rbf'}           0.418367   \n",
       "9        linear   {'C': 40, 'kernel': 'linear'}           0.520408   \n",
       "10          rbf      {'C': 50, 'kernel': 'rbf'}           0.408163   \n",
       "11       linear   {'C': 50, 'kernel': 'linear'}           0.517007   \n",
       "12          rbf      {'C': 60, 'kernel': 'rbf'}           0.421769   \n",
       "13       linear   {'C': 60, 'kernel': 'linear'}           0.517007   \n",
       "14          rbf      {'C': 70, 'kernel': 'rbf'}           0.425170   \n",
       "15       linear   {'C': 70, 'kernel': 'linear'}           0.537415   \n",
       "16          rbf      {'C': 80, 'kernel': 'rbf'}           0.431973   \n",
       "17       linear   {'C': 80, 'kernel': 'linear'}           0.544218   \n",
       "18          rbf      {'C': 90, 'kernel': 'rbf'}           0.445578   \n",
       "19       linear   {'C': 90, 'kernel': 'linear'}           0.540816   \n",
       "20          rbf     {'C': 100, 'kernel': 'rbf'}           0.448980   \n",
       "21       linear  {'C': 100, 'kernel': 'linear'}           0.554422   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.452381           0.482993           0.518771   \n",
       "1            0.442177           0.513605           0.518771   \n",
       "2            0.486395           0.496599           0.542662   \n",
       "3            0.513605           0.568027           0.549488   \n",
       "4            0.486395           0.489796           0.529010   \n",
       "5            0.554422           0.568027           0.559727   \n",
       "6            0.493197           0.510204           0.539249   \n",
       "7            0.557823           0.561224           0.559727   \n",
       "8            0.503401           0.506803           0.532423   \n",
       "9            0.561224           0.568027           0.559727   \n",
       "10           0.510204           0.506803           0.535836   \n",
       "11           0.591837           0.585034           0.559727   \n",
       "12           0.517007           0.482993           0.546075   \n",
       "13           0.585034           0.581633           0.569966   \n",
       "14           0.527211           0.489796           0.546075   \n",
       "15           0.612245           0.588435           0.576792   \n",
       "16           0.527211           0.486395           0.546075   \n",
       "17           0.622449           0.598639           0.576792   \n",
       "18           0.527211           0.496599           0.549488   \n",
       "19           0.625850           0.602041           0.569966   \n",
       "20           0.523810           0.500000           0.529010   \n",
       "21           0.632653           0.608844           0.580205   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.505119         0.470765        0.044226               21  \n",
       "1            0.505119         0.467363        0.061627               22  \n",
       "2            0.535836         0.491210        0.052977               17  \n",
       "3            0.542662         0.521151        0.047902               10  \n",
       "4            0.494881         0.479608        0.043567               20  \n",
       "5            0.552901         0.549056        0.020134                9  \n",
       "6            0.498294         0.488461        0.046385               19  \n",
       "7            0.552901         0.551777        0.012600                8  \n",
       "8            0.494881         0.491175        0.038496               18  \n",
       "9            0.556314         0.553140        0.016804                7  \n",
       "10           0.498294         0.491860        0.043681               16  \n",
       "11           0.556314         0.561984        0.026392                6  \n",
       "12           0.498294         0.493227        0.041461               15  \n",
       "13           0.563140         0.563356        0.024478                5  \n",
       "14           0.501706         0.497992        0.041352               14  \n",
       "15           0.559727         0.574923        0.025364                4  \n",
       "16           0.501706         0.498672        0.039167               13  \n",
       "17           0.559727         0.580365        0.027750                2  \n",
       "18           0.501706         0.504116        0.034874               11  \n",
       "19           0.559727         0.579680        0.030445                3  \n",
       "20           0.501706         0.500701        0.028327               12  \n",
       "21           0.556314         0.586487        0.030362                1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(clf.cv_results_)\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "usual-trash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.470765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.467363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.521151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.479608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.549056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.488461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.551777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.553140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.561984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.493227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.563356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.497992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.574923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.498672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.580365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.504116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.579680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.500701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.586487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score\n",
       "0        1          rbf         0.470765\n",
       "1        1       linear         0.467363\n",
       "2       10          rbf         0.491210\n",
       "3       10       linear         0.521151\n",
       "4       20          rbf         0.479608\n",
       "5       20       linear         0.549056\n",
       "6       30          rbf         0.488461\n",
       "7       30       linear         0.551777\n",
       "8       40          rbf         0.491175\n",
       "9       40       linear         0.553140\n",
       "10      50          rbf         0.491860\n",
       "11      50       linear         0.561984\n",
       "12      60          rbf         0.493227\n",
       "13      60       linear         0.563356\n",
       "14      70          rbf         0.497992\n",
       "15      70       linear         0.574923\n",
       "16      80          rbf         0.498672\n",
       "17      80       linear         0.580365\n",
       "18      90          rbf         0.504116\n",
       "19      90       linear         0.579680\n",
       "20     100          rbf         0.500701\n",
       "21     100       linear         0.586487"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "collect-gallery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5864874277355995"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "productive-compiler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-delta",
   "metadata": {},
   "source": [
    "Randmized search for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aquatic-connectivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.020408</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.559943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214.285714</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.616440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.897959</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.514307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285.714286</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.518398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367.346939</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.635504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>306.122449</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.521126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.408163</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.548376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>438.77551</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.634826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>357.142857</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.527260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>204.081633</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.613715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.204082</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.522512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>265.306122</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.628010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>326.530612</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.525894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>255.102041</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.625284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>234.693878</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.623250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>91.836735</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.581041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>51.020408</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>459.183673</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.530668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>418.367347</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.633468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>367.346939</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.526579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>132.653061</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.502742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_C param_kernel  mean_test_score\n",
       "0    51.020408       linear         0.559943\n",
       "1   214.285714       linear         0.616440\n",
       "2   244.897959          rbf         0.514307\n",
       "3   285.714286          rbf         0.518398\n",
       "4   367.346939       linear         0.635504\n",
       "5   306.122449          rbf         0.521126\n",
       "6    20.408163       linear         0.548376\n",
       "7    438.77551       linear         0.634826\n",
       "8   357.142857          rbf         0.527260\n",
       "9   204.081633       linear         0.613715\n",
       "10   10.204082       linear         0.522512\n",
       "11  265.306122       linear         0.628010\n",
       "12  326.530612          rbf         0.525894\n",
       "13  255.102041       linear         0.625284\n",
       "14  234.693878       linear         0.623250\n",
       "15   91.836735       linear         0.581041\n",
       "16   51.020408          rbf         0.491860\n",
       "17  459.183673          rbf         0.530668\n",
       "18  418.367347       linear         0.633468\n",
       "19  367.346939          rbf         0.526579\n",
       "20  132.653061          rbf         0.502742"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "        'C': np.linspace(0,500,50),\n",
    "        'kernel':['rbf','linear']\n",
    "    },\n",
    "    cv=5, #cross validation\n",
    "    return_train_score=False,\n",
    "    n_iter=21\n",
    ")\n",
    "rs.fit(X, df['type_of_opt'])\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "portuguese-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-composer",
   "metadata": {},
   "source": [
    "Choosing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "inside-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm':{\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params': {\n",
    "            'C': np.linspace(0,1000,50),\n",
    "            'kernel': ['rbf','linear']\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [0,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': np.linspace(0,1000,50)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "tender-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 226, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/saleksegid/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 277, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3d127026ed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type_of_opt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     scores.append({\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X, df['type_of_opt'])\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "direct-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "### abovel showes that svm has the higher score, therefore the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "southern-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (svm.SVC(kernel='linear', C=100),\n",
    "        svm.LinearSVC(C=100, max_iter=100),\n",
    "         svm.SVC(kernel='rbf', gamma=0.8, C=100),\n",
    "         svm.SVC(kernel='poly', degree=3, gamma='auto', C=100))\n",
    "\n",
    "models = (clf.fit(X, y) for clf in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-brooks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
