{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moving-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn import neighbors, datasets, svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('GTKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-agenda",
   "metadata": {},
   "source": [
    "pip install xlrd==1.2.0.  (latest version of xlrd only imports .xls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-association",
   "metadata": {},
   "source": [
    "The KNN classifier works on assigning the probability membership in a specifc class based on the distance to other members in a class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-hunter",
   "metadata": {},
   "source": [
    "The KNN algorithm randomly takes 80% of the data for training (X_train) and 20% of the data for testing (X_test). Inorder to make the randomization cosistent every time the model is run, a seed of 14 is chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-rental",
   "metadata": {},
   "source": [
    "After fitting the data into the algorithm, the model predicts the assigned_class of the optimzer inroder to help the user chose the type of optimzer they want to utilize for theor specific needs. i.e type of function, number of parametrs, accuracy and time per trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divided-stereo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-36f5b1f1bff7>:1: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  df = pd.read_excel ('data/All Data combined.xlsx')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel ('data/All Data combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organized-improvement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "measured-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "X = df[['number of trials','accuracy [calc. max/ actual max]','time per trial [s]']]\n",
    "y = df['assigned_class']\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dimensional-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050 450\n"
     ]
    }
   ],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                        random_state=14) #14 is seed\n",
    "\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heavy-reducing",
   "metadata": {},
   "source": [
    "since the data in each dimension of X should be scaled similarly for the model, the below code rescales the features. This minimizes the the bias in which dimensioanlity can drastically favor closseness in arbitary dimensions of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genuine-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graduate-bible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12807   ,  1.1675019 ,  1.04447895],\n",
       "       [ 0.44115322, -0.23317503, -0.44693361],\n",
       "       [ 1.58601452,  0.47840222, -0.45067036],\n",
       "       ...,\n",
       "       [ 0.21218096, -0.93891383, -0.43515322],\n",
       "       [ 0.44115322,  0.55631219, -0.42495643],\n",
       "       [-0.0167913 , -0.90518099, -0.4261909 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-stations",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medical-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_neighbors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removed-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2, weights='distance')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the model: Init K-NN\n",
    "# We create an instance of Neighbours Classifier and fit it to the training data.\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(K_neighbors, weights='distance')\n",
    "\n",
    "# Here we fit it to the data - it figures out the assigned_classes and \n",
    "# which training X points belong to each class in Y \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "based-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] euclidean 1050\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_, clf.effective_metric_, clf.n_samples_fit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adverse-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted classes [4 3 2 3 3 0 2 1 1 1 4 3 3 4 2 1 0 0 1 1 0 2 4 3 2 0 2 1 2 1 4 2 2 4 4 4 1\n",
      " 4 2 3 0 3 0 3 3 1 4 2 4 2 3 4 4 4 2 1 1 3 4 4 4 1 2 4 1 0 1 2 4 2 2 4 1 3\n",
      " 4 0 3 4 3 4 2 4 0 1 0 2 0 4 1 3 4 2 1 0 1 0 2 0 1 3 1 4 1 4 2 3 1 3 2 3 2\n",
      " 0 0 0 0 1 2 0 0 2 3 1 1 4 2 4 4 3 1 1 0 3 1 1 0 1 4 2 4 1 4 4 0 0 2 3 3 0\n",
      " 1 3 3 4 1 2 3 2 1 0 1 0 3 4 1 4 4 0 0 0 1 3 3 1 1 1 4 4 4 4 3 4 1 3 4 1 4\n",
      " 2 2 1 2 1 3 0 3 2 2 0 3 3 3 4 4 3 4 0 2 1 0 0 0 2 1 3 2 4 0 1 3 0 1 3 1 0\n",
      " 3 1 1 3 0 0 4 1 3 3 1 0 4 2 2 2 3 2 0 3 2 1 4 1 2 4 0 1 1 1 4 2 4 3 4 2 4\n",
      " 1 4 4 1 4 1 3 4 4 3 1 2 3 3 4 0 0 2 4 4 1 4 0 0 1 2 1 3 0 0 2 2 1 1 0 3 3\n",
      " 3 1 4 2 3 3 3 4 1 1 1 0 2 1 2 4 2 0 1 2 4 1 1 0 0 4 1 2 3 4 4 0 1 3 2 4 0\n",
      " 4 4 0 1 2 1 2 0 2 4 2 2 1 0 4 2 0 2 0 2 4 1 0 0 3 0 1 2 1 1 0 2 1 3 1 1 3\n",
      " 2 4 0 2 4 4 3 1 1 2 2 0 4 4 0 0 4 2 2 2 1 1 0 3 3 1 2 1 1 3 4 3 3 4 1 1 1\n",
      " 3 3 1 1 3 2 0 2 1 4 2 4 2 0 3 1 3 4 4 1 3 3 1 1 1 1 3 0 2 0 1 0 4 2 2 0 3\n",
      " 2 3 3 3 2 1]\n",
      "KNN probability of belonging to class [[0.         0.         0.         0.         1.        ]\n",
      " [0.         0.         0.41704556 0.58295444 0.        ]\n",
      " [0.         0.         1.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.         0.        ]\n",
      " [0.         0.68363293 0.31636707 0.         0.        ]]\n",
      "Mean accuracy of prediction 0.5688888888888889\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set results\n",
    "y_test_predicted = clf.predict(X_test)\n",
    "y_test_probabilities = clf.predict_proba(X_test)\n",
    "mean_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"predicted classes\", y_test_predicted)\n",
    "print(\"KNN probability of belonging to class\",y_test_probabilities)\n",
    "print(\"Mean accuracy of prediction\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extended-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1444444444444444"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "assumed-breath",
   "metadata": {},
   "source": [
    "A confusion matrix is a matrix that can be used to measure the performance of a machine learning algorithm. Each row of the matrix represents the instances of an actual assigned_class and each column represents the instances of a predicted class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47 13  6 11  0  0]\n",
      " [10 45 24 15  0  0]\n",
      " [14 28 34 20  0  0]\n",
      " [ 7 24 22 37  0  0]\n",
      " [ 0  0  0  0 93  0]\n",
      " [ 0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "cm = confusion_matrix(y_test, y_test_predicted, labels=[0,1,2,3,4,5])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-vector",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "greenhouse-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    \"\"\"Precision is the fraction of cases where the algorith correctly predicted assigned_class \n",
    "       out of all instances where the algorithm predicted (correctly and incorrectly)\"\"\"\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "\n",
    "def recall(label, confusion_matrix):\n",
    "    \"\"\"recall is the fraction of cases where the algorithm correctly predicted out of all of \n",
    "       the cases which are labelled as a specific assigned_class\"\"\"\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    \"\"\"calculates the precision for the whole classification problem calculates\"\"\"\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    \"\"\"calculates the recall for the whole classification problem calculates\"\"\"\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "authentic-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label precision recall\n",
      "    0     0.603  0.610\n",
      "    1     0.409  0.479\n",
      "    2     0.395  0.354\n",
      "    3     0.446  0.411\n",
      "    4     1.000  1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"label precision recall\")\n",
    "for label in range(5):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "capital-windsor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5688888888888889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "accuracy(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
