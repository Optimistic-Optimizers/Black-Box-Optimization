{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number of trials</th>\n",
       "      <th>number of parameters</th>\n",
       "      <th>type of function</th>\n",
       "      <th>accuracy [calc. max/ actual max]</th>\n",
       "      <th>time per trial [s]</th>\n",
       "      <th>type_of_opt</th>\n",
       "      <th>assigned_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.732417</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.638160</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.284646</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  number of trials  number of parameters type of function  \\\n",
       "0            0.0                16                     2             Trig   \n",
       "1            1.0                13                     2             Trig   \n",
       "2            2.0                10                     2             Trig   \n",
       "3            3.0                18                     2             Trig   \n",
       "4            4.0                11                     2             Trig   \n",
       "...          ...               ...                   ...              ...   \n",
       "1345         NaN                 8                     2             Trig   \n",
       "1346         NaN                 8                     2             Trig   \n",
       "1347         NaN                14                     2             Trig   \n",
       "1348         NaN                 9                     2             Trig   \n",
       "1349         NaN                10                     2             Trig   \n",
       "\n",
       "      accuracy [calc. max/ actual max]  time per trial [s] type_of_opt  \\\n",
       "0                             0.732417            0.009824       CmaEs   \n",
       "1                             0.983980            0.008316       CmaEs   \n",
       "2                             0.638160            0.007854       CmaEs   \n",
       "3                             0.952784            0.009196       CmaEs   \n",
       "4                             0.284646            0.007938       CmaEs   \n",
       "...                                ...                 ...         ...   \n",
       "1345                          0.034904            0.007662      CMA-ES   \n",
       "1346                          0.091423            0.010617      CMA-ES   \n",
       "1347                          0.015566            0.019561      CMA-ES   \n",
       "1348                          0.076210            0.011982      CMA-ES   \n",
       "1349                          0.028620            0.021816      CMA-ES   \n",
       "\n",
       "      assigned_class  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1345               5  \n",
       "1346               5  \n",
       "1347               5  \n",
       "1348               5  \n",
       "1349               5  \n",
       "\n",
       "[1350 rows x 8 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Data/All Data combined.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.drop(['type_of_opt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['accuracy [calc. max/ actual max]'] < 1.05]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['number of trials','number of parameters','accuracy [calc. max/ actual max]', 'time per trial [s]']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['type_of_opt'].replace('CmaEs', 1,inplace=True)\n",
    "#df['type_of_opt'].replace('Random', 2,inplace=True)\n",
    "#df['type_of_opt'].replace('TPE', 3,inplace=True)\n",
    "y = df['assigned_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test = StandardScaler().fit(x_test).transform(x_test)\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 4)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,4), ncols = 4)\n",
    "ax[0].hist(x_train[:,0], bins = 20)\n",
    "ax[0].set_title('n_trials')\n",
    "ax[1].hist(x_train[:,1], bins = 20)\n",
    "ax[1].set_title('n_parameters')\n",
    "ax[2].hist(x_train[:,2], bins = 20)\n",
    "ax[2].set_title('accuracy')\n",
    "ax[3].hist(x_train[:,3], bins = 20)\n",
    "ax[3].set_title('time per trial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 22.78   \u001b[0m | \u001b[0m 36.65   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 22.77   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.6633  \u001b[0m | \u001b[95m 7.202   \u001b[0m | \u001b[95m 40.77   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 38.72   \u001b[0m | \u001b[0m 48.54   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6608  \u001b[0m | \u001b[0m 31.14   \u001b[0m | \u001b[0m 34.84   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.6858  \u001b[0m | \u001b[95m 6.717   \u001b[0m | \u001b[95m 41.64   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 3.414   \u001b[0m | \u001b[0m 16.43   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 32.58   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 11.89   \u001b[0m | \u001b[0m 16.46   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 19.8    \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 5.027   \u001b[0m | \u001b[0m 23.11   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 36.93   \u001b[0m | \u001b[0m 8.95    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 4.637   \u001b[0m | \u001b[0m 49.1    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 37.33   \u001b[0m | \u001b[0m 15.18   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 4.239   \u001b[0m | \u001b[0m 21.38   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 27.44   \u001b[0m | \u001b[0m 21.24   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 26.85   \u001b[0m | \u001b[0m 19.73   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 15.81   \u001b[0m | \u001b[0m 31.75   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 44.21   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 8.56    \u001b[0m | \u001b[0m 6.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 7.279   \u001b[0m | \u001b[0m 42.16   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6783  \u001b[0m | \u001b[0m 5.884   \u001b[0m | \u001b[0m 41.75   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 6.411   \u001b[0m | \u001b[0m 41.06   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 43.76   \u001b[0m | \u001b[0m 35.43   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6708  \u001b[0m | \u001b[0m 6.329   \u001b[0m | \u001b[0m 41.96   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6534  \u001b[0m | \u001b[0m 7.204   \u001b[0m | \u001b[0m 41.62   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 6.013   \u001b[0m | \u001b[0m 41.5    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6608  \u001b[0m | \u001b[0m 6.685   \u001b[0m | \u001b[0m 42.0    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 43.16   \u001b[0m | \u001b[0m 44.68   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 33.32   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 2.204   \u001b[0m | \u001b[0m 31.49   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 41.86   \u001b[0m | \u001b[0m 17.31   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 5.179   \u001b[0m | \u001b[0m 42.06   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 5.968   \u001b[0m | \u001b[0m 42.14   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6683  \u001b[0m | \u001b[0m 7.606   \u001b[0m | \u001b[0m 40.23   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 25.92   \u001b[0m | \u001b[0m 7.613   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 46.76   \u001b[0m | \u001b[0m 35.99   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 7.092   \u001b[0m | \u001b[0m 40.23   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 14.51   \u001b[0m | \u001b[0m 36.68   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6658  \u001b[0m | \u001b[0m 7.929   \u001b[0m | \u001b[0m 39.69   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 7.899   \u001b[0m | \u001b[0m 39.67   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 34.84   \u001b[0m | \u001b[0m 3.553   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 19.59   \u001b[0m | \u001b[0m 8.465   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 5.437   \u001b[0m | \u001b[0m 24.23   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 18.46   \u001b[0m | \u001b[0m 3.824   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 45.19   \u001b[0m | \u001b[0m 35.72   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 6.635   \u001b[0m | \u001b[0m 4.51    \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.3641  \u001b[0m | \u001b[0m 1.279   \u001b[0m | \u001b[0m 15.63   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 40.24   \u001b[0m | \u001b[0m 24.25   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 6.741   \u001b[0m | \u001b[0m 41.75   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 6.717497714390575, f: 0.6683291770573566\n",
      "Found y: 41.63592762570041, f: 0.6683291770573566\n",
      "Max value found is: 0.6608478802992519\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    estimator = DecisionTreeClassifier(max_depth= int(np.round(x)))\n",
    "    clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(y)))\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    yhat = clf.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=int(np.round(found_x)))\n",
    "clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(found_y)))\n",
    "clf = clf.fit(x_train, y_train)\n",
    "yhat = clf.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655860349127182"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0.4, 0. ]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0,0.4,0]).reshape(1,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 66.29   \u001b[0m | \u001b[0m 88.38   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6534  \u001b[0m | \u001b[95m 70.73   \u001b[0m | \u001b[95m 10.22   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 75.2    \u001b[0m | \u001b[0m 30.0    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 86.63   \u001b[0m | \u001b[0m 3.527   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 17.59   \u001b[0m | \u001b[0m 87.02   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 2.558   \u001b[0m | \u001b[0m 44.02   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 95.92   \u001b[0m | \u001b[0m 85.44   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 97.37   \u001b[0m | \u001b[0m 92.55   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 29.28   \u001b[0m | \u001b[0m 13.81   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 82.16   \u001b[0m | \u001b[0m 5.028   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.6608  \u001b[0m | \u001b[95m 9.654   \u001b[0m | \u001b[95m 59.4    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 17.27   \u001b[0m | \u001b[0m 47.67   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 49.99   \u001b[0m | \u001b[0m 87.8    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 32.78   \u001b[0m | \u001b[0m 94.38   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 48.52   \u001b[0m | \u001b[0m 64.54   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.6633  \u001b[0m | \u001b[95m 95.83   \u001b[0m | \u001b[95m 59.12   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 24.42   \u001b[0m | \u001b[0m 51.86   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 85.84   \u001b[0m | \u001b[0m 25.66   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 10.26   \u001b[0m | \u001b[0m 89.5    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 63.65   \u001b[0m | \u001b[0m 5.963   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 95.38   \u001b[0m | \u001b[0m 66.32   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 96.17   \u001b[0m | \u001b[0m 55.67   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 92.51   \u001b[0m | \u001b[0m 59.23   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 99.22   \u001b[0m | \u001b[0m 59.5    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 59.76   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 62.59   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 10.77   \u001b[0m | \u001b[0m 56.43   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 6.591   \u001b[0m | \u001b[0m 60.32   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 71.25   \u001b[0m | \u001b[0m 13.73   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6534  \u001b[0m | \u001b[0m 95.56   \u001b[0m | \u001b[0m 61.44   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 70.62   \u001b[0m | \u001b[0m 7.249   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6633  \u001b[0m | \u001b[0m 7.204   \u001b[0m | \u001b[0m 58.06   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 4.63    \u001b[0m | \u001b[0m 57.53   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 8.543   \u001b[0m | \u001b[0m 58.98   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 11.03   \u001b[0m | \u001b[0m 59.73   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 96.7    \u001b[0m | \u001b[0m 60.26   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 94.82   \u001b[0m | \u001b[0m 59.69   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 96.25   \u001b[0m | \u001b[0m 58.26   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.6633  \u001b[0m | \u001b[0m 7.302   \u001b[0m | \u001b[0m 58.94   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 6.732   \u001b[0m | \u001b[0m 58.6    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6459  \u001b[0m | \u001b[0m 7.447   \u001b[0m | \u001b[0m 57.29   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 9.488   \u001b[0m | \u001b[0m 60.59   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 7.877   \u001b[0m | \u001b[0m 58.01   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6509  \u001b[0m | \u001b[0m 9.886   \u001b[0m | \u001b[0m 58.46   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 95.24   \u001b[0m | \u001b[0m 58.42   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 13.12   \u001b[0m | \u001b[0m 58.9    \u001b[0m |\n",
      "| \u001b[95m 47      \u001b[0m | \u001b[95m 0.6683  \u001b[0m | \u001b[95m 7.424   \u001b[0m | \u001b[95m 59.62   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 7.654   \u001b[0m | \u001b[0m 60.62   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 13.19   \u001b[0m | \u001b[0m 60.79   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 8.433   \u001b[0m | \u001b[0m 59.94   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 7.4235167133427336, f: 0.6633416458852868\n",
      "Found y: 59.623936663391646, f: 0.6683291770573566\n",
      "Max value found is: 0.6658354114713217\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    rfr = RandomForestClassifier(max_depth = int(np.round(x)), n_estimators = int(np.round(y)), max_features = 4)\n",
    "    rfr = rfr.fit(x_train, y_train.flatten())\n",
    "    yhat = rfr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 100\n",
    "ymin = 1\n",
    "ymax = 100\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=4)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestClassifier(max_depth = int(np.round(found_x)), n_estimators = int(np.round(found_y)), max_features = 4)\n",
    "rfr = rfr.fit(x_train, y_train.flatten())\n",
    "yhat = rfr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0773067331670823"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6234413965087282"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 43.54   \u001b[0m | \u001b[0m 38.76   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6135  \u001b[0m | \u001b[95m 36.1    \u001b[0m | \u001b[95m 7.907   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 27.7    \u001b[0m | \u001b[0m 14.3    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 2.98    \u001b[0m | \u001b[0m 19.92   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5586  \u001b[0m | \u001b[0m 11.01   \u001b[0m | \u001b[0m 18.39   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 17.5    \u001b[0m | \u001b[0m 28.94   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 30.86   \u001b[0m | \u001b[0m 40.26   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 25.1    \u001b[0m | \u001b[0m 28.37   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 36.97   \u001b[0m | \u001b[0m 16.41   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 22.97   \u001b[0m | \u001b[0m 20.89   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 15.54   \u001b[0m | \u001b[0m 12.23   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 36.57   \u001b[0m | \u001b[0m 29.02   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 37.7    \u001b[0m | \u001b[0m 39.65   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 45.51   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 24.86   \u001b[0m | \u001b[0m 32.98   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 8.138   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5362  \u001b[0m | \u001b[0m 1.773   \u001b[0m | \u001b[0m 27.95   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 28.59   \u001b[0m | \u001b[0m 8.707   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 45.89   \u001b[0m | \u001b[0m 13.92   \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.6185  \u001b[0m | \u001b[95m 5.453   \u001b[0m | \u001b[95m 3.903   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.6284  \u001b[0m | \u001b[95m 44.46   \u001b[0m | \u001b[95m 5.567   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 42.13   \u001b[0m | \u001b[0m 9.403   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 40.17   \u001b[0m | \u001b[0m 2.959   \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 0.6309  \u001b[0m | \u001b[95m 49.63   \u001b[0m | \u001b[95m 8.509   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 49.42   \u001b[0m | \u001b[0m 1.145   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 9.995   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 33.25   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 3.577   \u001b[0m | \u001b[0m 9.104   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 44.04   \u001b[0m | \u001b[0m 1.162   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 20.06   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 24.89   \u001b[0m | \u001b[0m 1.071   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 21.47   \u001b[0m | \u001b[0m 8.093   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 48.59   \u001b[0m | \u001b[0m 5.062   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 46.6    \u001b[0m | \u001b[0m 9.29    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5262  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 49.91   \u001b[0m | \u001b[0m 12.26   \u001b[0m |\n",
      "| \u001b[95m 40      \u001b[0m | \u001b[95m 0.6359  \u001b[0m | \u001b[95m 29.83   \u001b[0m | \u001b[95m 3.174   \u001b[0m |\n",
      "| \u001b[95m 41      \u001b[0m | \u001b[95m 0.6459  \u001b[0m | \u001b[95m 32.35   \u001b[0m | \u001b[95m 4.809   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 34.81   \u001b[0m | \u001b[0m 4.65    \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 37.0    \u001b[0m | \u001b[0m 49.78   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 32.67   \u001b[0m | \u001b[0m 6.54    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 39.37   \u001b[0m | \u001b[0m 6.305   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 18.94   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6334  \u001b[0m | \u001b[0m 25.99   \u001b[0m | \u001b[0m 5.279   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 31.45   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.5212  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 38.43   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 22.59   \u001b[0m | \u001b[0m 13.42   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 32.3499628455739, f: 0.6408977556109726\n",
      "Found y: 4.80912996056861, f: 0.6234413965087282\n",
      "Max value found is: 0.6359102244389028\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    gbr = GradientBoostingClassifier(n_estimators = int(np.round(x)), max_depth = int(np.round(y)), learning_rate = 0.1)\n",
    "    gbr = gbr.fit(x_train, y_train.flatten())\n",
    "    yhat = gbr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators = int(np.round(found_x)), max_depth = int(np.round(found_y)), learning_rate = 0.1)\n",
    "gbr = gbr.fit(x_train, y_train.flatten())\n",
    "yhat = gbr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3216957605985038"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6408977556109726"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
