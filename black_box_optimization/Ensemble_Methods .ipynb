{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/All Data combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of trials</th>\n",
       "      <th>number of parameters</th>\n",
       "      <th>type of function</th>\n",
       "      <th>accuracy [calc. max/ actual max]</th>\n",
       "      <th>time per trial [s]</th>\n",
       "      <th>assigned_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.732417</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.638160</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.284646</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052639</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037169</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085693</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number of trials  number of parameters type of function  \\\n",
       "0                 16.0                   2.0             Trig   \n",
       "1                 13.0                   2.0             Trig   \n",
       "2                 10.0                   2.0             Trig   \n",
       "3                 18.0                   2.0             Trig   \n",
       "4                 11.0                   2.0             Trig   \n",
       "...                ...                   ...              ...   \n",
       "1245               9.0                   2.0           linear   \n",
       "1246              10.0                   2.0           linear   \n",
       "1247               7.0                   2.0           linear   \n",
       "1248              17.0                   2.0           linear   \n",
       "1249              16.0                   2.0           linear   \n",
       "\n",
       "      accuracy [calc. max/ actual max]  time per trial [s]  assigned_class  \n",
       "0                             0.732417            0.009824             0.0  \n",
       "1                             0.983980            0.008316             0.0  \n",
       "2                             0.638160            0.007854             0.0  \n",
       "3                             0.952784            0.009196             0.0  \n",
       "4                             0.284646            0.007938             0.0  \n",
       "...                                ...                 ...             ...  \n",
       "1245                          1.000000            0.052639             3.0  \n",
       "1246                          1.000000            0.006312             3.0  \n",
       "1247                          1.000000            0.037169             3.0  \n",
       "1248                          1.000000            0.116375             3.0  \n",
       "1249                          1.000000            0.085693             3.0  \n",
       "\n",
       "[1250 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.drop(['Unnamed: 8'], axis=1)\n",
    "df = df.drop(['type_of_opt'], axis=1)\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['accuracy [calc. max/ actual max]'] < 1.05]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['number of trials','number of parameters','accuracy [calc. max/ actual max]', 'time per trial [s]']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['assigned_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of trials</th>\n",
       "      <th>number of parameters</th>\n",
       "      <th>accuracy [calc. max/ actual max]</th>\n",
       "      <th>time per trial [s]</th>\n",
       "      <th>assigned_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1249.000000</td>\n",
       "      <td>1249.000000</td>\n",
       "      <td>1249.000000</td>\n",
       "      <td>1249.000000</td>\n",
       "      <td>1249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.842274</td>\n",
       "      <td>3.039231</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>1.561249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.441205</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.360821</td>\n",
       "      <td>0.019479</td>\n",
       "      <td>1.134244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.161572</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.469765</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.870366</td>\n",
       "      <td>0.019677</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136035</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number of trials  number of parameters  \\\n",
       "count       1249.000000           1249.000000   \n",
       "mean          10.842274              3.039231   \n",
       "std            4.441205              0.999630   \n",
       "min            1.000000              2.000000   \n",
       "25%            8.000000              2.000000   \n",
       "50%           11.000000              4.000000   \n",
       "75%           14.000000              4.000000   \n",
       "max           25.000000              4.000000   \n",
       "\n",
       "       accuracy [calc. max/ actual max]  time per trial [s]  assigned_class  \n",
       "count                       1249.000000         1249.000000     1249.000000  \n",
       "mean                           0.502171            0.018106        1.561249  \n",
       "std                            0.360821            0.019479        1.134244  \n",
       "min                            0.000000            0.003163        0.000000  \n",
       "25%                            0.161572            0.007464        1.000000  \n",
       "50%                            0.469765            0.010050        2.000000  \n",
       "75%                            0.870366            0.019677        3.000000  \n",
       "max                            1.000000            0.136035        3.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test = StandardScaler().fit(x_test).transform(x_test)\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(874, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,4), ncols = 4)\n",
    "ax[0].hist(x_train[:,0], bins = 20)\n",
    "ax[0].set_title('n_trials')\n",
    "ax[1].hist(x_train[:,1], bins = 20)\n",
    "ax[1].set_title('n_parameters')\n",
    "ax[2].hist(x_train[:,2], bins = 20)\n",
    "ax[2].set_title('accuracy')\n",
    "ax[3].hist(x_train[:,3], bins = 20)\n",
    "ax[3].set_title('time per trial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 46.41   \u001b[0m | \u001b[0m 49.32   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6693  \u001b[0m | \u001b[95m 17.88   \u001b[0m | \u001b[95m 42.5    \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 35.97   \u001b[0m | \u001b[0m 4.318   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 28.94   \u001b[0m | \u001b[0m 40.31   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6613  \u001b[0m | \u001b[0m 11.41   \u001b[0m | \u001b[0m 19.16   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 21.97   \u001b[0m | \u001b[0m 13.41   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.68    \u001b[0m | \u001b[95m 27.68   \u001b[0m | \u001b[95m 33.85   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 49.54   \u001b[0m | \u001b[0m 36.65   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6747  \u001b[0m | \u001b[0m 46.43   \u001b[0m | \u001b[0m 35.2    \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6453  \u001b[0m | \u001b[0m 26.97   \u001b[0m | \u001b[0m 28.98   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6773  \u001b[0m | \u001b[0m 43.88   \u001b[0m | \u001b[0m 8.003   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 7.625   \u001b[0m | \u001b[0m 10.7    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 33.65   \u001b[0m | \u001b[0m 7.678   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6427  \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 20.31   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 34.98   \u001b[0m | \u001b[0m 35.02   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6293  \u001b[0m | \u001b[0m 3.514   \u001b[0m | \u001b[0m 45.71   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 35.68   \u001b[0m | \u001b[0m 7.088   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 13.14   \u001b[0m | \u001b[0m 6.006   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.4427  \u001b[0m | \u001b[0m 1.143   \u001b[0m | \u001b[0m 20.89   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 22.24   \u001b[0m | \u001b[0m 16.46   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 31.29   \u001b[0m | \u001b[0m 14.45   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6347  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 4.746   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 26.45   \u001b[0m | \u001b[0m 5.317   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6427  \u001b[0m | \u001b[0m 20.35   \u001b[0m | \u001b[0m 35.25   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.68    \u001b[0m | \u001b[0m 41.52   \u001b[0m | \u001b[0m 40.65   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.672   \u001b[0m | \u001b[0m 37.22   \u001b[0m | \u001b[0m 47.4    \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 21.15   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 41.23   \u001b[0m | \u001b[0m 30.34   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 2.993   \u001b[0m | \u001b[0m 1.86    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 13.61   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6453  \u001b[0m | \u001b[0m 29.69   \u001b[0m | \u001b[0m 49.51   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 13.59   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 47.65   \u001b[0m | \u001b[0m 12.7    \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 16.68   \u001b[0m | \u001b[0m 23.99   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6693  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 27.7    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 37.52   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6507  \u001b[0m | \u001b[0m 36.21   \u001b[0m | \u001b[0m 41.56   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6533  \u001b[0m | \u001b[0m 46.84   \u001b[0m | \u001b[0m 42.58   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.576   \u001b[0m | \u001b[0m 19.3    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 30.26   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.4427  \u001b[0m | \u001b[0m 1.099   \u001b[0m | \u001b[0m 36.34   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 43.37   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6453  \u001b[0m | \u001b[0m 41.32   \u001b[0m | \u001b[0m 13.46   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.656   \u001b[0m | \u001b[0m 40.1    \u001b[0m | \u001b[0m 49.92   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.4427  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.6747  \u001b[0m | \u001b[0m 34.93   \u001b[0m | \u001b[0m 24.92   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 33.12   \u001b[0m | \u001b[0m 30.01   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.6027  \u001b[0m | \u001b[0m 43.76   \u001b[0m | \u001b[0m 1.037   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.68    \u001b[0m | \u001b[0m 29.15   \u001b[0m | \u001b[0m 21.82   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 23.39   \u001b[0m | \u001b[0m 44.13   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 27.682599015249494, f: 0.6533333333333333\n",
      "Found y: 33.85120167710989, f: 0.6666666666666666\n",
      "Max value found is: 0.6906666666666667\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    estimator = DecisionTreeClassifier(max_depth= int(np.round(x)))\n",
    "    clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(y)))\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    yhat = clf.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=int(np.round(found_x)))\n",
    "clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(found_y)))\n",
    "clf = clf.fit(x_train, y_train)\n",
    "yhat = clf.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826666666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0.4, 0. ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0,0.4,0]).reshape(1,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = int(a[0])\n",
    "if category == 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6107  \u001b[0m | \u001b[0m 56.41   \u001b[0m | \u001b[0m 27.0    \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 46.75   \u001b[0m | \u001b[0m 73.54   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.616   \u001b[0m | \u001b[95m 45.85   \u001b[0m | \u001b[95m 72.22   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 88.8    \u001b[0m | \u001b[0m 18.67   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6133  \u001b[0m | \u001b[0m 82.33   \u001b[0m | \u001b[0m 50.7    \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6133  \u001b[0m | \u001b[0m 31.1    \u001b[0m | \u001b[0m 16.86   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.624   \u001b[0m | \u001b[95m 88.93   \u001b[0m | \u001b[95m 70.15   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 20.38   \u001b[0m | \u001b[0m 50.99   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 45.92   \u001b[0m | \u001b[0m 98.64   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 4.87    \u001b[0m | \u001b[0m 44.46   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 59.37   \u001b[0m | \u001b[0m 22.72   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6053  \u001b[0m | \u001b[0m 28.69   \u001b[0m | \u001b[0m 21.88   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5973  \u001b[0m | \u001b[0m 46.71   \u001b[0m | \u001b[0m 90.05   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 27.28   \u001b[0m | \u001b[0m 96.84   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6053  \u001b[0m | \u001b[0m 71.48   \u001b[0m | \u001b[0m 58.2    \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.6267  \u001b[0m | \u001b[95m 30.83   \u001b[0m | \u001b[95m 22.86   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6107  \u001b[0m | \u001b[0m 23.06   \u001b[0m | \u001b[0m 29.78   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6027  \u001b[0m | \u001b[0m 23.39   \u001b[0m | \u001b[0m 25.05   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 82.27   \u001b[0m | \u001b[0m 67.76   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 52.43   \u001b[0m | \u001b[0m 80.49   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 37.27   \u001b[0m | \u001b[0m 22.28   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 58.19   \u001b[0m | \u001b[0m 63.75   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 88.92   \u001b[0m | \u001b[0m 18.71   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.592   \u001b[0m | \u001b[0m 41.41   \u001b[0m | \u001b[0m 5.266   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 34.16   \u001b[0m | \u001b[0m 7.269   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6133  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 83.86   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 79.0    \u001b[0m | \u001b[0m 71.33   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 4.225   \u001b[0m | \u001b[0m 52.83   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5947  \u001b[0m | \u001b[0m 16.5    \u001b[0m | \u001b[0m 24.06   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 7.063   \u001b[0m | \u001b[0m 17.16   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 68.13   \u001b[0m | \u001b[0m 76.3    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 79.84   \u001b[0m | \u001b[0m 70.2    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 30.48   \u001b[0m | \u001b[0m 96.22   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6133  \u001b[0m | \u001b[0m 22.54   \u001b[0m | \u001b[0m 53.9    \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6267  \u001b[0m | \u001b[0m 82.73   \u001b[0m | \u001b[0m 62.02   \u001b[0m |\n",
      "| \u001b[95m 36      \u001b[0m | \u001b[95m 0.6293  \u001b[0m | \u001b[95m 26.86   \u001b[0m | \u001b[95m 84.17   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6267  \u001b[0m | \u001b[0m 84.92   \u001b[0m | \u001b[0m 62.05   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 46.95   \u001b[0m | \u001b[0m 81.16   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 59.33   \u001b[0m | \u001b[0m 47.0    \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 41.59   \u001b[0m | \u001b[0m 1.823   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6293  \u001b[0m | \u001b[0m 56.07   \u001b[0m | \u001b[0m 38.76   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6053  \u001b[0m | \u001b[0m 57.96   \u001b[0m | \u001b[0m 30.21   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 89.87   \u001b[0m | \u001b[0m 41.79   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 60.28   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5813  \u001b[0m | \u001b[0m 5.294   \u001b[0m | \u001b[0m 4.218   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.592   \u001b[0m | \u001b[0m 46.2    \u001b[0m | \u001b[0m 13.14   \u001b[0m |\n",
      "| \u001b[95m 47      \u001b[0m | \u001b[95m 0.6373  \u001b[0m | \u001b[95m 7.622   \u001b[0m | \u001b[95m 44.22   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 17.81   \u001b[0m | \u001b[0m 70.24   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 31.68   \u001b[0m | \u001b[0m 21.75   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5867  \u001b[0m | \u001b[0m 17.19   \u001b[0m | \u001b[0m 4.733   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 7.622453435977801, f: 0.6106666666666667\n",
      "Found y: 44.22401995812902, f: 0.6133333333333333\n",
      "Max value found is: 0.6373333333333333\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    rfr = RandomForestClassifier(max_depth = int(np.round(x)), n_estimators = int(np.round(y)), max_features = 4)\n",
    "    rfr = rfr.fit(x_train, y_train.flatten())\n",
    "    yhat = rfr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 100\n",
    "ymin = 1\n",
    "ymax = 100\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=4)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestClassifier(max_depth = int(np.round(found_x)), n_estimators = int(np.round(found_y)), max_features = 4)\n",
    "rfr = rfr.fit(x_train, y_train.flatten())\n",
    "yhat = rfr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def func(x,y):\n",
    "    gbr = GradientBoostingClassifier(n_estimators = int(np.round(x)), max_depth = int(np.round(y)), learning_rate = 0.1)\n",
    "    gbr = gbr.fit(x_train, y_train.flatten())\n",
    "    yhat = gbr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators = int(np.round(found_x)), max_depth = int(np.round(found_y)), learning_rate = 0.1)\n",
    "gbr = gbr.fit(x_train, y_train.flatten())\n",
    "yhat = gbr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run the predictions from the Ensemble method to generate predictions based on the number of trials, accuracy, and time of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(b):\n",
    "    n = 11 #Number of points per dimension. Number of trials = n^3\n",
    "    prediction_list = []\n",
    "    prediction_parameters = []\n",
    "    for k in range(n):\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                a = k/(n-1)\n",
    "                c = j/(n-1)\n",
    "                d = i/(n-1)\n",
    "                predict_array = np.array([a,b,c,d]).reshape(1,-1)\n",
    "                prediction = clf.predict(predict_array)\n",
    "                prediction_parameters.append([a,c,d])\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "    p_class = np.asarray(prediction_list)\n",
    "    p_parameters = np.asarray(prediction_parameters)\n",
    "    data = np.hstack((p_parameters, p_class))\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, view_angle_h, view_angle_v):\n",
    "    cols = ['Trials', 'Accuracy', 'Time', 'Class']\n",
    "    df = pd.DataFrame(data, columns = cols)\n",
    "    \n",
    "    class_0_data = np.asarray(df[df['Class'] == 0.])\n",
    "    class_1_data = np.asarray(df[df['Class'] == 1.])\n",
    "    class_2_data = np.asarray(df[df['Class'] == 2.])\n",
    "    class_3_data = np.asarray(df[df['Class'] == 3.])\n",
    "    \n",
    "    plt.close()\n",
    "    fig = plt.subplots(figsize=(15,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    xline_0 = class_0_data[:,0]\n",
    "    yline_0 = class_0_data[:,1]\n",
    "    zline_0 = class_0_data[:,2]\n",
    "    ax.scatter3D(xline_0, yline_0, zline_0, color = 'b', marker='o', s=300, alpha = 0.25, label = 'CmaEs')\n",
    "\n",
    "    xline_1 = class_1_data[:,0]\n",
    "    yline_1 = class_1_data[:,1]\n",
    "    zline_1 = class_1_data[:,2]\n",
    "    ax.scatter3D(xline_1, yline_1, zline_1, color = 'y', marker='o', s=300, alpha = 0.25, label = 'Random')\n",
    "\n",
    "    xline_2 = class_2_data[:,0]\n",
    "    yline_2 = class_2_data[:,1]\n",
    "    zline_2 = class_2_data[:,2]\n",
    "    ax.scatter3D(xline_2, yline_2, zline_2, color = 'g', marker='o', s =300, alpha = 0.25, label = 'TPE')\n",
    "\n",
    "    xline_3 = class_3_data[:,0]\n",
    "    yline_3 = class_3_data[:,1]\n",
    "    zline_3 = class_3_data[:,2]\n",
    "    ax.scatter3D(xline_3, yline_3, zline_3, color = 'r', marker='o', s=300, alpha = 0.25, label = 'Bayes')\n",
    "\n",
    "\n",
    "    plt.legend(loc = 'upper right')\n",
    "    ax.set_xlabel('Number of Trials')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Time per Iteration')\n",
    "    ax.view_init(elev= view_angle_v, azim=view_angle_h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = generate_data(0)\n",
    "data_1 = generate_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30007010e402464aaccab8b0e67a6f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=40, description='Rotate_View_h', max=360, min=40, step=20), IntSlider(vaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "def update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0):\n",
    "    if N_of_Params == 0:\n",
    "        plot_data(data_0, Rotate_View_h, Rotate_View_v)\n",
    "    else:\n",
    "        plot_data(data_1, Rotate_View_h, Rotate_View_v)\n",
    "interact(update, Rotate_View_h = (40,360,20), Rotate_View_v = (10,360,20), N_of_Params = (0,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing from python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_methods import decision_tree_classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
