{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number of trials</th>\n",
       "      <th>number of parameters</th>\n",
       "      <th>type of function</th>\n",
       "      <th>accuracy [calc. max/ actual max]</th>\n",
       "      <th>time per trial [s]</th>\n",
       "      <th>type_of_opt</th>\n",
       "      <th>assigned_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.732417</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.983980</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.638160</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.284646</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>CmaEs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Trig</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>CMA-ES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  number of trials  number of parameters type of function  \\\n",
       "0            0.0                16                     2             Trig   \n",
       "1            1.0                13                     2             Trig   \n",
       "2            2.0                10                     2             Trig   \n",
       "3            3.0                18                     2             Trig   \n",
       "4            4.0                11                     2             Trig   \n",
       "...          ...               ...                   ...              ...   \n",
       "1345         NaN                 8                     2             Trig   \n",
       "1346         NaN                 8                     2             Trig   \n",
       "1347         NaN                14                     2             Trig   \n",
       "1348         NaN                 9                     2             Trig   \n",
       "1349         NaN                10                     2             Trig   \n",
       "\n",
       "      accuracy [calc. max/ actual max]  time per trial [s] type_of_opt  \\\n",
       "0                             0.732417            0.009824       CmaEs   \n",
       "1                             0.983980            0.008316       CmaEs   \n",
       "2                             0.638160            0.007854       CmaEs   \n",
       "3                             0.952784            0.009196       CmaEs   \n",
       "4                             0.284646            0.007938       CmaEs   \n",
       "...                                ...                 ...         ...   \n",
       "1345                          0.034904            0.007662      CMA-ES   \n",
       "1346                          0.091423            0.010617      CMA-ES   \n",
       "1347                          0.015566            0.019561      CMA-ES   \n",
       "1348                          0.076210            0.011982      CMA-ES   \n",
       "1349                          0.028620            0.021816      CMA-ES   \n",
       "\n",
       "      assigned_class  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1345               0  \n",
       "1346               0  \n",
       "1347               0  \n",
       "1348               0  \n",
       "1349               0  \n",
       "\n",
       "[1350 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/All Data combined.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.drop(['type_of_opt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['accuracy [calc. max/ actual max]'] < 1.05]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['number of trials','number of parameters','accuracy [calc. max/ actual max]', 'time per trial [s]']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['type_of_opt'].replace('CmaEs', 1,inplace=True)\n",
    "#df['type_of_opt'].replace('Random', 2,inplace=True)\n",
    "#df['type_of_opt'].replace('TPE', 3,inplace=True)\n",
    "y = df['assigned_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test = StandardScaler().fit(x_test).transform(x_test)\n",
    "x_train = MinMaxScaler().fit(x_train).transform(x_train)\n",
    "x_test = MinMaxScaler().fit(x_test).transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,4), ncols = 4)\n",
    "ax[0].hist(x_train[:,0], bins = 20)\n",
    "ax[0].set_title('n_trials')\n",
    "ax[1].hist(x_train[:,1], bins = 20)\n",
    "ax[1].set_title('n_parameters')\n",
    "ax[2].hist(x_train[:,2], bins = 20)\n",
    "ax[2].set_title('accuracy')\n",
    "ax[3].hist(x_train[:,3], bins = 20)\n",
    "ax[3].set_title('time per trial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 33.5    \u001b[0m | \u001b[0m 25.78   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 4.202   \u001b[0m | \u001b[0m 49.22   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 37.69   \u001b[0m | \u001b[0m 5.346   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.6185  \u001b[0m | \u001b[95m 34.92   \u001b[0m | \u001b[95m 32.77   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 41.29   \u001b[0m | \u001b[0m 49.33   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 41.83   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.6234  \u001b[0m | \u001b[95m 46.56   \u001b[0m | \u001b[95m 43.4    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 40.79   \u001b[0m | \u001b[0m 38.68   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 24.82   \u001b[0m | \u001b[0m 3.822   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 48.91   \u001b[0m | \u001b[0m 28.95   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 38.25   \u001b[0m | \u001b[0m 29.17   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 30.51   \u001b[0m | \u001b[0m 27.47   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 24.66   \u001b[0m | \u001b[0m 28.91   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 9.601   \u001b[0m | \u001b[0m 4.617   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 8.237   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 10.72   \u001b[0m | \u001b[0m 31.28   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 5.866   \u001b[0m | \u001b[0m 6.763   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 26.7    \u001b[0m | \u001b[0m 44.66   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 22.83   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 37.52   \u001b[0m | \u001b[0m 42.75   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 34.95   \u001b[0m | \u001b[0m 32.82   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 0.6309  \u001b[0m | \u001b[95m 37.04   \u001b[0m | \u001b[95m 28.23   \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 0.6534  \u001b[0m | \u001b[95m 47.44   \u001b[0m | \u001b[95m 10.66   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 9.857   \u001b[0m | \u001b[0m 42.19   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 34.26   \u001b[0m | \u001b[0m 20.99   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 48.21   \u001b[0m | \u001b[0m 24.66   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 47.7    \u001b[0m | \u001b[0m 7.428   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 20.01   \u001b[0m | \u001b[0m 20.16   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6284  \u001b[0m | \u001b[0m 33.07   \u001b[0m | \u001b[0m 16.63   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 39.97   \u001b[0m | \u001b[0m 9.076   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 46.08   \u001b[0m | \u001b[0m 48.5    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 5.035   \u001b[0m | \u001b[0m 9.861   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 18.99   \u001b[0m | \u001b[0m 47.67   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 38.84   \u001b[0m | \u001b[0m 47.69   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 6.946   \u001b[0m | \u001b[0m 46.22   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 6.814   \u001b[0m | \u001b[0m 12.26   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 39.46   \u001b[0m | \u001b[0m 27.01   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 19.01   \u001b[0m | \u001b[0m 4.266   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 39.97   \u001b[0m | \u001b[0m 17.35   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 11.47   \u001b[0m | \u001b[0m 31.68   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 5.73    \u001b[0m | \u001b[0m 47.9    \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 20.86   \u001b[0m | \u001b[0m 31.06   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 13.21   \u001b[0m | \u001b[0m 12.13   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 6.767   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 6.203   \u001b[0m | \u001b[0m 34.2    \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 25.35   \u001b[0m | \u001b[0m 26.33   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 41.16   \u001b[0m | \u001b[0m 31.52   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 45.77   \u001b[0m | \u001b[0m 48.89   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 44.33   \u001b[0m | \u001b[0m 14.84   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 7.796   \u001b[0m | \u001b[0m 6.764   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 47.43566686803625, f: 0.5960099750623441\n",
      "Found y: 10.66080494644188, f: 0.6059850374064838\n",
      "Max value found is: 0.6259351620947631\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    estimator = DecisionTreeClassifier(max_depth= int(np.round(x)))\n",
    "    clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(y)))\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    yhat = clf.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=int(np.round(found_x)))\n",
    "clf = BaggingClassifier(base_estimator=estimator, n_estimators= int(np.round(found_y)))\n",
    "clf = clf.fit(x_train, y_train)\n",
    "yhat = clf.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6159600997506235"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0.4, 0. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0,0.4,0]).reshape(1,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 92.55   \u001b[0m | \u001b[0m 65.43   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 74.1    \u001b[0m | \u001b[0m 17.15   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 6.937   \u001b[0m | \u001b[0m 6.898   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 53.16   \u001b[0m | \u001b[0m 65.04   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 74.63   \u001b[0m | \u001b[0m 84.99   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 85.86   \u001b[0m | \u001b[0m 10.49   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 80.37   \u001b[0m | \u001b[0m 65.29   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 88.18   \u001b[0m | \u001b[0m 9.232   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 73.24   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 2.18    \u001b[0m | \u001b[0m 64.59   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 33.58   \u001b[0m | \u001b[0m 40.35   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 21.38   \u001b[0m | \u001b[0m 33.24   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.6209  \u001b[0m | \u001b[95m 90.8    \u001b[0m | \u001b[95m 8.891   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 83.7    \u001b[0m | \u001b[0m 19.94   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5711  \u001b[0m | \u001b[0m 85.24   \u001b[0m | \u001b[0m 2.201   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 17.39   \u001b[0m | \u001b[0m 65.37   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 79.21   \u001b[0m | \u001b[0m 46.9    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 50.17   \u001b[0m | \u001b[0m 78.63   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 67.18   \u001b[0m | \u001b[0m 19.16   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 85.44   \u001b[0m | \u001b[0m 99.11   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 93.93   \u001b[0m | \u001b[0m 8.669   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 82.35   \u001b[0m | \u001b[0m 95.19   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 89.68   \u001b[0m | \u001b[0m 96.08   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 93.13   \u001b[0m | \u001b[0m 13.67   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 89.53   \u001b[0m | \u001b[0m 61.05   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 89.17   \u001b[0m | \u001b[0m 69.54   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 96.86   \u001b[0m | \u001b[0m 69.12   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 95.77   \u001b[0m | \u001b[0m 4.015   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 81.25   \u001b[0m | \u001b[0m 99.85   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 95.91   \u001b[0m | \u001b[0m 62.64   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 62.6    \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 67.26   \u001b[0m | \u001b[0m 24.07   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 66.09   \u001b[0m | \u001b[0m 14.75   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 88.66   \u001b[0m | \u001b[0m 65.09   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 85.89   \u001b[0m | \u001b[0m 96.36   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 28.71   \u001b[0m | \u001b[0m 37.9    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 35.14   \u001b[0m | \u001b[0m 35.31   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 38.61   \u001b[0m | \u001b[0m 38.09   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 31.57   \u001b[0m | \u001b[0m 32.06   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 38.68   \u001b[0m | \u001b[0m 32.03   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 86.04   \u001b[0m | \u001b[0m 25.84   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.616   \u001b[0m | \u001b[0m 80.6    \u001b[0m | \u001b[0m 25.14   \u001b[0m |\n",
      "| \u001b[95m 43      \u001b[0m | \u001b[95m 0.6234  \u001b[0m | \u001b[95m 81.98   \u001b[0m | \u001b[95m 30.42   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.6135  \u001b[0m | \u001b[0m 77.78   \u001b[0m | \u001b[0m 30.09   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 85.65   \u001b[0m | \u001b[0m 33.05   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 79.61   \u001b[0m | \u001b[0m 34.4    \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 82.52   \u001b[0m | \u001b[0m 27.8    \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 82.46   \u001b[0m | \u001b[0m 87.17   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 80.09   \u001b[0m | \u001b[0m 80.29   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 24.36   \u001b[0m | \u001b[0m 64.99   \u001b[0m |\n",
      "=================================================\n",
      "Found x: 81.98033154046779, f: 0.6234413965087282\n",
      "Found y: 30.421759038852848, f: 0.6059850374064838\n",
      "Max value found is: 0.6034912718204489\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    rfr = RandomForestClassifier(max_depth = int(np.round(x)), n_estimators = int(np.round(y)), max_features = 4)\n",
    "    rfr = rfr.fit(x_train, y_train.flatten())\n",
    "    yhat = rfr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 100\n",
    "ymin = 1\n",
    "ymax = 100\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=4)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestClassifier(max_depth = int(np.round(found_x)), n_estimators = int(np.round(found_y)), max_features = 4)\n",
    "rfr = rfr.fit(x_train, y_train.flatten())\n",
    "yhat = rfr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1546134663341645"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134663341645885"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 42.57   \u001b[0m | \u001b[0m 4.973   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5586  \u001b[0m | \u001b[0m 30.13   \u001b[0m | \u001b[0m 14.48   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 25.6    \u001b[0m | \u001b[0m 33.0    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5362  \u001b[0m | \u001b[0m 8.931   \u001b[0m | \u001b[0m 47.16   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 38.98   \u001b[0m | \u001b[0m 44.74   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.611   \u001b[0m | \u001b[95m 46.79   \u001b[0m | \u001b[95m 2.067   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5337  \u001b[0m | \u001b[0m 7.575   \u001b[0m | \u001b[0m 14.93   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 1.839   \u001b[0m | \u001b[0m 21.83   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5337  \u001b[0m | \u001b[0m 5.658   \u001b[0m | \u001b[0m 43.31   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 37.17   \u001b[0m | \u001b[0m 15.09   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5387  \u001b[0m | \u001b[0m 47.52   \u001b[0m | \u001b[0m 40.88   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 18.58   \u001b[0m | \u001b[0m 4.313   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 21.46   \u001b[0m | \u001b[0m 23.88   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5387  \u001b[0m | \u001b[0m 11.27   \u001b[0m | \u001b[0m 35.44   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 41.45   \u001b[0m | \u001b[0m 41.65   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 26.26   \u001b[0m | \u001b[0m 46.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 33.33   \u001b[0m | \u001b[0m 3.981   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5262  \u001b[0m | \u001b[0m 2.727   \u001b[0m | \u001b[0m 7.244   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 34.55   \u001b[0m | \u001b[0m 17.85   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 22.98   \u001b[0m | \u001b[0m 40.57   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 24.16   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 41.39   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 6.594   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.601   \u001b[0m | \u001b[0m 21.56   \u001b[0m | \u001b[0m 8.942   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5611  \u001b[0m | \u001b[0m 13.78   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 46.46   \u001b[0m | \u001b[0m 5.867   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 16.81   \u001b[0m | \u001b[0m 9.055   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.6209  \u001b[0m | \u001b[95m 26.15   \u001b[0m | \u001b[95m 6.488   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 23.37   \u001b[0m | \u001b[0m 5.578   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 28.77   \u001b[0m | \u001b[0m 7.484   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5835  \u001b[0m | \u001b[0m 27.41   \u001b[0m | \u001b[0m 4.112   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 25.3    \u001b[0m | \u001b[0m 9.245   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 12.25   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5337  \u001b[0m | \u001b[0m 37.45   \u001b[0m | \u001b[0m 29.64   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 49.85   \u001b[0m | \u001b[0m 49.78   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 37.85   \u001b[0m | \u001b[0m 5.417   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5761  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 32.47   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.611   \u001b[0m | \u001b[0m 45.3    \u001b[0m | \u001b[0m 10.39   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 41.75   \u001b[0m | \u001b[0m 8.884   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5561  \u001b[0m | \u001b[0m 45.73   \u001b[0m | \u001b[0m 14.59   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 36.34   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 47.59   \u001b[0m | \u001b[0m 8.965   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5212  \u001b[0m | \u001b[0m 19.05   \u001b[0m | \u001b[0m 14.95   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5337  \u001b[0m | \u001b[0m 17.92   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 19.96   \u001b[0m | \u001b[0m 1.029   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5661  \u001b[0m | \u001b[0m 20.24   \u001b[0m | \u001b[0m 6.564   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 5.678   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5661  \u001b[0m | \u001b[0m 12.33   \u001b[0m | \u001b[0m 8.35    \u001b[0m |\n",
      "=================================================\n",
      "Found x: 26.15042829601712, f: 0.6134663341645885\n",
      "Found y: 6.488250902849805, f: 0.5960099750623441\n",
      "Max value found is: 0.5985037406483791\n"
     ]
    }
   ],
   "source": [
    "def func(x,y):\n",
    "    gbr = GradientBoostingClassifier(n_estimators = int(np.round(x)), max_depth = int(np.round(y)), learning_rate = 0.1)\n",
    "    gbr = gbr.fit(x_train, y_train.flatten())\n",
    "    yhat = gbr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test, yhat)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    \n",
    "    return  acc\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xmin = 1\n",
    "xmax = 50\n",
    "ymin = 1\n",
    "ymax = 50\n",
    "\n",
    "pbounds = {'x': (xmin, xmax), 'y': (ymin, ymax)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=func, pbounds=pbounds, verbose=3)\n",
    "\n",
    "optimizer.maximize(init_points = 20, n_iter = 30)\n",
    "    \n",
    "best_params = optimizer.max[\"params\"]\n",
    "    \n",
    "found_x = best_params['x']\n",
    "found_y = best_params['y']\n",
    "\n",
    "max_value = func(found_x, found_y)\n",
    "    \n",
    "print(\"Found x: {}, f: {}\".format(found_x, (func(found_x, found_y))))\n",
    "print(\"Found y: {}, f: {}\".format(found_y, (func(found_x, found_y))))\n",
    "print(\"Max value found is: {}\".format(max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators = int(np.round(found_x)), max_depth = int(np.round(found_y)), learning_rate = 0.1)\n",
    "gbr = gbr.fit(x_train, y_train.flatten())\n",
    "yhat = gbr.predict(x_test)\n",
    "MSE = mean_squared_error(y_test, yhat)\n",
    "acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1172069825436408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5960099750623441"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run the predictions from the Ensemble method to generate predictions based on the number of trials, accuracy, and time of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(b):\n",
    "    n = 11 #Number of points per dimension. Number of trials = n^3\n",
    "    prediction_list = []\n",
    "    prediction_parameters = []\n",
    "    for k in range(n):\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                a = k/(n-1)\n",
    "                c = j/(n-1)\n",
    "                d = i/(n-1)\n",
    "                predict_array = np.array([a,b,c,d]).reshape(1,-1)\n",
    "                prediction = clf.predict(predict_array)\n",
    "                prediction_parameters.append([a,c,d])\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "    p_class = np.asarray(prediction_list)\n",
    "    p_parameters = np.asarray(prediction_parameters)\n",
    "    data = np.hstack((p_parameters, p_class))\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, view_angle_h, view_angle_v):\n",
    "    cols = ['Trials', 'Accuracy', 'Time', 'Class']\n",
    "    df = pd.DataFrame(data, columns = cols)\n",
    "    \n",
    "    class_0_data = np.asarray(df[df['Class'] == 0.])\n",
    "    class_1_data = np.asarray(df[df['Class'] == 1.])\n",
    "    class_2_data = np.asarray(df[df['Class'] == 2.])\n",
    "    class_3_data = np.asarray(df[df['Class'] == 3.])\n",
    "    class_4_data = np.asarray(df[df['Class'] == 4.])\n",
    "    \n",
    "    plt.close()\n",
    "    fig = plt.subplots(figsize=(15,10))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    xline_0 = class_0_data[:,0]\n",
    "    yline_0 = class_0_data[:,1]\n",
    "    zline_0 = class_0_data[:,2]\n",
    "    ax.scatter3D(xline_0, yline_0, zline_0, color = 'b', marker='o', s=300, alpha = 0.25, label = 'CmaEs')\n",
    "\n",
    "    xline_1 = class_1_data[:,0]\n",
    "    yline_1 = class_1_data[:,1]\n",
    "    zline_1 = class_1_data[:,2]\n",
    "    ax.scatter3D(xline_1, yline_1, zline_1, color = 'm', marker='o', s=300, alpha = 0.25, label = 'Random')\n",
    "\n",
    "    xline_2 = class_2_data[:,0]\n",
    "    yline_2 = class_2_data[:,1]\n",
    "    zline_2 = class_2_data[:,2]\n",
    "    ax.scatter3D(xline_2, yline_2, zline_2, color = 'g', marker='o', s =300, alpha = 0.25, label = 'TPE')\n",
    "\n",
    "    xline_3 = class_3_data[:,0]\n",
    "    yline_3 = class_3_data[:,1]\n",
    "    zline_3 = class_3_data[:,2]\n",
    "    ax.scatter3D(xline_3, yline_3, zline_3, color = 'r', marker='o', s=300, alpha = 0.25, label = 'Bayes')\n",
    "\n",
    "    xline_4 = class_4_data[:,0]\n",
    "    yline_4 = class_4_data[:,1]\n",
    "    zline_4 = class_4_data[:,2]\n",
    "    ax.scatter3D(xline_4, yline_4, zline_4, color = 'y', marker='o', s=300, alpha = 0.25, label = 'L-BFGS-B')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    ax.set_xlabel('Number of Trials')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_zlabel('Time per Iteration')\n",
    "    ax.view_init(elev= view_angle_v, azim=view_angle_h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = generate_data(0)\n",
    "data_1 = generate_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bda5d68f13419fbc7ef9da4fbbdbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=40, description='Rotate_View_h', max=360, min=40, step=20), IntSlider(vaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "def update(Rotate_View_h=0, Rotate_View_v=0, N_of_Params=0):\n",
    "    if N_of_Params == 0:\n",
    "        plot_data(data_0, Rotate_View_h, Rotate_View_v)\n",
    "    else:\n",
    "        plot_data(data_1, Rotate_View_h, Rotate_View_v)\n",
    "interact(update, Rotate_View_h = (40,360,20), Rotate_View_v = (10,360,20), N_of_Params = (0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_methods import decision_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     x     |     y     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3852  \u001b[0m | \u001b[0m 7.157   \u001b[0m | \u001b[0m 8.549   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3383  \u001b[0m | \u001b[0m 49.62   \u001b[0m | \u001b[0m 44.67   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3358  \u001b[0m | \u001b[0m 31.62   \u001b[0m | \u001b[0m 29.52   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.3481  \u001b[0m | \u001b[0m 17.33   \u001b[0m | \u001b[0m 6.321   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.4914  \u001b[0m | \u001b[95m 3.325   \u001b[0m | \u001b[95m 21.73   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3432  \u001b[0m | \u001b[0m 45.13   \u001b[0m | \u001b[0m 24.21   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 5.481   \u001b[0m | \u001b[0m 18.86   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.3358  \u001b[0m | \u001b[0m 46.8    \u001b[0m | \u001b[0m 48.92   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3901  \u001b[0m | \u001b[0m 4.968   \u001b[0m | \u001b[0m 46.94   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3728  \u001b[0m | \u001b[0m 32.38   \u001b[0m | \u001b[0m 38.57   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.3309  \u001b[0m | \u001b[0m 29.54   \u001b[0m | \u001b[0m 43.9    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.3259  \u001b[0m | \u001b[0m 13.87   \u001b[0m | \u001b[0m 41.65   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3531  \u001b[0m | \u001b[0m 20.93   \u001b[0m | \u001b[0m 20.17   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3432  \u001b[0m | \u001b[0m 14.68   \u001b[0m | \u001b[0m 34.28   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.316   \u001b[0m | \u001b[0m 37.77   \u001b[0m | \u001b[0m 42.67   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.3679  \u001b[0m | \u001b[0m 47.99   \u001b[0m | \u001b[0m 11.26   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3185  \u001b[0m | \u001b[0m 34.25   \u001b[0m | \u001b[0m 43.0    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.321   \u001b[0m | \u001b[0m 30.17   \u001b[0m | \u001b[0m 32.43   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.3012  \u001b[0m | \u001b[0m 35.24   \u001b[0m | \u001b[0m 18.5    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 18.8    \u001b[0m | \u001b[0m 34.37   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.5654  \u001b[0m | \u001b[95m 2.175   \u001b[0m | \u001b[95m 22.49   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 0.5679  \u001b[0m | \u001b[95m 2.015   \u001b[0m | \u001b[95m 23.86   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.2667  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 22.91   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.5654  \u001b[0m | \u001b[0m 2.163   \u001b[0m | \u001b[0m 23.85   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.442   \u001b[0m | \u001b[0m 2.397   \u001b[0m | \u001b[0m 23.18   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 30.65   \u001b[0m | \u001b[0m 24.08   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.3358  \u001b[0m | \u001b[0m 31.47   \u001b[0m | \u001b[0m 40.63   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5086  \u001b[0m | \u001b[0m 3.162   \u001b[0m | \u001b[0m 49.53   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5679  \u001b[0m | \u001b[0m 2.119   \u001b[0m | \u001b[0m 21.95   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.4568  \u001b[0m | \u001b[0m 2.609   \u001b[0m | \u001b[0m 22.15   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.3037  \u001b[0m | \u001b[0m 2.12    \u001b[0m | \u001b[0m 22.0    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.3309  \u001b[0m | \u001b[0m 43.15   \u001b[0m | \u001b[0m 23.88   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.3383  \u001b[0m | \u001b[0m 33.46   \u001b[0m | \u001b[0m 37.45   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 17.96   \u001b[0m | \u001b[0m 30.87   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.3383  \u001b[0m | \u001b[0m 30.27   \u001b[0m | \u001b[0m 14.31   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.3556  \u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 11.89   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 49.29   \u001b[0m | \u001b[0m 34.55   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 22.48   \u001b[0m | \u001b[0m 14.9    \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.358   \u001b[0m | \u001b[0m 12.04   \u001b[0m | \u001b[0m 11.33   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.3679  \u001b[0m | \u001b[0m 36.46   \u001b[0m | \u001b[0m 4.66    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.321   \u001b[0m | \u001b[0m 41.55   \u001b[0m | \u001b[0m 11.37   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.4543  \u001b[0m | \u001b[0m 32.12   \u001b[0m | \u001b[0m 4.205   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.4519  \u001b[0m | \u001b[0m 2.873   \u001b[0m | \u001b[0m 22.87   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.3383  \u001b[0m | \u001b[0m 36.16   \u001b[0m | \u001b[0m 18.84   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.3556  \u001b[0m | \u001b[0m 27.2    \u001b[0m | \u001b[0m 27.15   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.3259  \u001b[0m | \u001b[0m 15.2    \u001b[0m | \u001b[0m 13.52   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.3728  \u001b[0m | \u001b[0m 49.79   \u001b[0m | \u001b[0m 20.18   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.3309  \u001b[0m | \u001b[0m 23.77   \u001b[0m | \u001b[0m 33.49   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.3309  \u001b[0m | \u001b[0m 5.847   \u001b[0m | \u001b[0m 48.82   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.321   \u001b[0m | \u001b[0m 37.04   \u001b[0m | \u001b[0m 31.88   \u001b[0m |\n",
      "=================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_classifier(1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
